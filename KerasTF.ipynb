{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras & Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Random initialization\n",
    "import numpy as np\n",
    "np.random.seed(98643)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(683)\n",
    "# Uncomment this to hide TF warnings about allocation\n",
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# An image clearing dependencies\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n",
    "                                 denoise_wavelet, estimate_sigma, denoise_tv_bregman, denoise_nl_means)\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Data reading and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Training part\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that images, that provided in a dataset are very noisy and if we will get rid of granular noise, we will be able to predict better and construct noisy dataset by our own.\n",
    "\n",
    "It is also interesting to train a denoising autoencoder on dataset in order to extract some global features that may be used further on model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate data to an image format\n",
    "def color_composite(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        rgb_arrays.append(rgb)\n",
    "    return np.array(rgb_arrays)\n",
    "\n",
    "def denoise(X, weight, multichannel):\n",
    "    return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n",
    "\n",
    "def smooth(X, sigma):\n",
    "    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n",
    "\n",
    "def grayscale(X):\n",
    "    return np.asarray([rgb2gray(item) for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../ShipIceberg/Data/train.json\")\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "train_all = True\n",
    "\n",
    "# These are train flags that required to train model more efficiently and \n",
    "# select proper model parameters\n",
    "train_b = True or train_all\n",
    "train_img = True or train_all\n",
    "train_total = True or train_all\n",
    "predict_submission = True and train_all\n",
    "\n",
    "clean_all = True\n",
    "clean_b = True or clean_all\n",
    "clean_img = True or clean_all\n",
    "\n",
    "load_all = False\n",
    "load_b = False or load_all\n",
    "load_img = False or load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n",
    "                   weight_rgb=0.05, weight_gray=0.05):\n",
    "    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n",
    "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n",
    "    band_1 = to_arr(band_1)\n",
    "    band_2 = to_arr(band_2)\n",
    "    band_3 = (band_1 + band_2) / 2\n",
    "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n",
    "    # Make a picture format from flat vector\n",
    "    band_1 = gray_reshape(band_1)\n",
    "    band_2 = gray_reshape(band_2)\n",
    "    band_3 = gray_reshape(band_3)\n",
    "    print('Denoising and reshaping')\n",
    "    if train_b and clean_b:\n",
    "        # Smooth and denoise data\n",
    "        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n",
    "        print('Gray 1 done')\n",
    "        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n",
    "        print('Gray 2 done')\n",
    "        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n",
    "        print('Gray 3 done')\n",
    "    if train_img and clean_img:\n",
    "        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n",
    "    print('RGB done')\n",
    "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n",
    "    band_1 = tf_reshape(band_1)\n",
    "    band_2 = tf_reshape(band_2)\n",
    "    band_3 = tf_reshape(band_3)\n",
    "    #images = tf_reshape(images)\n",
    "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n",
    "    X_angle = np.array(frame.inc_angle)\n",
    "    if labeled:\n",
    "        y = np.array(frame[\"is_iceberg\"])\n",
    "    else:\n",
    "        y = None\n",
    "    return y, X_angle, band, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising and reshaping\n",
      "Gray 1 done\n",
      "Gray 2 done\n",
      "Gray 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/skimage/filters/_gaussian.py:108: RuntimeWarning: Images with dimensions (M, N, 3) are interpreted as 2D+RGB by default. Use `multichannel=False` to interpret as 3D image with last dimension of length 3.\n",
      "  warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB done\n"
     ]
    }
   ],
   "source": [
    "y_train, X_angles, X_b, X_images = create_dataset(train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(200, figsize=(15, 15))\n",
    "random_indicies = np.random.choice(range(len(X_images)), 9, False)\n",
    "subset = X_images[random_indicies]\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "band_1_x = train['band_1'].values\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = np.asarray([np.asarray(item).reshape(75, 75) for item in subset])\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = smooth(denoise(np.asarray(\n",
    "    [np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False), 0.5)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model itself consists of 3 convolutional neural networks. Two basic networks and one combined. The idea is to train two basic networks on different data representations and after that, using trained convolutional layers in combination to train common network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_notebook(angle, lr, decay, channels, relu_type='relu'):\n",
    "    # angle variable defines if we should use angle parameter or ignore it\n",
    "    input_1 = Input(shape=(75, 75, channels))\n",
    "    input_2 = Input(shape=[1])\n",
    "\n",
    "    fcnn = Conv2D(32, kernel_size=(3, 3), activation=relu_type)(input_1)\n",
    "    fcnn = MaxPooling2D((3, 3))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(64, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Flatten()(fcnn)\n",
    "    if angle:\n",
    "        local_input = [input_1, input_2]\n",
    "    else:\n",
    "        local_input = input_1\n",
    "    dense = Dropout(0.2)(fcnn)\n",
    "    dense = Dense(256, activation=relu_type)(dense)\n",
    "    partial_model = Model(input_1, fcnn)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(128, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(64, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    # For some reason i've decided not to normalize angle data\n",
    "    if angle:\n",
    "        dense = Concatenate()([dense, input_2])\n",
    "    else:\n",
    "        dense = dense\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    model = Model(local_input, output)\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model, partial_model\n",
    "\n",
    "def combined_model(m_b, m_img, lr, decay):\n",
    "    input_b = Input(shape=(75, 75, 3))\n",
    "    input_img = Input(shape=(75, 75, 3))\n",
    "    input_angular = Input(shape=[1])\n",
    "\n",
    "    # I've never tested non-trainable source models tho\n",
    "    #for layer in m_b.layers:\n",
    "    #    layer.trainable = False\n",
    "    #for layer in m_img.layers:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    m1 = m_b(input_b)\n",
    "    m2 = m_img(input_img)\n",
    "\n",
    "    # So, combine models and train perceptron based on that\n",
    "    # The iteresting idea is to use XGB for this task, but i actually hate this method\n",
    "    common = Concatenate()([m1, m2])\n",
    "    common = BatchNormalization()(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(2048, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(1024, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(512, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Concatenate()([common, BatchNormalization()(input_angular)])\n",
    "    output = Dense(1, activation=\"sigmoid\")(common)\n",
    "    model = Model([input_b, input_img, input_angular], output)\n",
    "   # optimizer = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n",
    "    optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def train_model(model, batch_size, epochs, checkpoint_name, X_train, y_train, verbose=2, val_data=None, val_split=0.15):\n",
    "    callbacks = [ModelCheckpoint(checkpoint_name, save_best_only=True, monitor='val_loss')]\n",
    "    try:\n",
    "        if val_data is None:\n",
    "            model.fit(X_train, y_train, epochs=epochs, validation_split=val_split,\n",
    "                      batch_size=batch_size, callbacks=callbacks, verbose=verbose, shuffle=True)\n",
    "        else:\n",
    "            x_val, y_val = val_data\n",
    "            model.fit(X_train, y_train, epochs=epochs, validation_data=[x_val, y_val],\n",
    "                      batch_size=batch_size, callbacks=callbacks, verbose=verbose, shuffle=True)\n",
    "    except KeyboardInterrupt:\n",
    "        if verbose > 0:\n",
    "            print('Interrupted')\n",
    "    if verbose > 0:\n",
    "        print('Loading model')\n",
    "    model.load_weights(filepath=checkpoint_name)\n",
    "    return model\n",
    "\n",
    "def get_angular_status(angle, x, x_a):\n",
    "    if angle:\n",
    "        result = [x, x_a]\n",
    "    else:\n",
    "        result = x\n",
    "    return result\n",
    "\n",
    "\n",
    "#Train a particular model\n",
    "def gen_model_weights(angle, lr, decay, channels, relu, batch_size, epochs, path_name, data, only_load=False, verbose=2):\n",
    "    X_train, X_angle_train, y_train, X_val, X_angles_val, y_val = data\n",
    "    X_train, X_angle_train, y_train = shuffle(X_train, X_angle_train, y_train, random_state=np.random.randint(1, 123))\n",
    "    model, partial_model = get_model_notebook(angle, lr, decay, channels, relu)\n",
    "    if only_load:\n",
    "        model.load_weights(path_name)\n",
    "        return model, partial_model\n",
    "    model = train_model(model, batch_size, epochs, path_name,\n",
    "                           get_angular_status(angle, X_train, X_angle_train), y_train, verbose=verbose)\n",
    "\n",
    "    if verbose > 0:\n",
    "        loss_val, acc_val = model.evaluate(get_angular_status(angle, X_val, X_angles_val), y_val,\n",
    "                               verbose=0, batch_size=batch_size)\n",
    "\n",
    "        loss_train, acc_train = model.evaluate(get_angular_status(angle, X_train, X_angle_train), y_train,\n",
    "                                       verbose=0, batch_size=batch_size)\n",
    "\n",
    "        print('Val/Train Loss:', str(loss_val) + '/' + str(loss_train), \\\n",
    "            'Val/Train Acc:', str(acc_val) + '/' + str(acc_train))\n",
    "    return model, partial_model\n",
    "\n",
    "\n",
    "# Train all 3 models\n",
    "def train_models(dataset, lr, batch_size, max_epoch, verbose=2, return_model=False):\n",
    "    X_angles, y_train, X_b, X_images = dataset\n",
    "    angle_b = True\n",
    "    angle_images = True\n",
    "    X_angles, X_angles_val,\\\n",
    "    y_train, y_val,\\\n",
    "    X_b, X_b_val,\\\n",
    "    X_images, X_images_val = train_test_split(X_angles, y_train, X_b, X_images, random_state=687, train_size=0.9)\n",
    "\n",
    "    if train_b:\n",
    "        if verbose > 0:\n",
    "            print('Training bandwidth network')\n",
    "        data_b1 = (X_b, X_angles, y_train, X_b_val, X_angles_val, y_val)\n",
    "        model_b, model_b_cut = gen_model_weights(angle_b, lr, 0, 3, 'relu', batch_size, max_epoch, 'model_b',\n",
    "                                             data_b1, only_load=load_b, verbose=verbose)\n",
    "\n",
    "    if train_img:\n",
    "        if verbose > 0:\n",
    "            print('Training image network')\n",
    "        data_images = (X_images, X_angles, y_train, X_b_val, X_angles_val, y_val)\n",
    "        model_images, model_images_cut = gen_model_weights(angle_images, lr, 0, 3, 'relu', batch_size, max_epoch, 'model_img',\n",
    "                                                       data_images, only_load=load_img, verbose=verbose)\n",
    "\n",
    "    if train_total:\n",
    "        common_model = combined_model(model_b_cut, model_images_cut, lr, 0)\n",
    "        common_x_train = [X_b, X_images, X_angles]\n",
    "        common_y_train = y_train\n",
    "        common_x_val = [X_b_val, X_images_val, X_angles_val]\n",
    "        common_y_val = y_val\n",
    "        if verbose > 0:\n",
    "            print('Training common network')\n",
    "        common_model = train_model(common_model, batch_size, max_epoch, 'common_check', common_x_train,\n",
    "                           common_y_train, verbose=verbose, val_split=0.2)\n",
    "\n",
    "        loss_val, acc_val = common_model.evaluate(common_x_val, common_y_val,\n",
    "                                           verbose=0, batch_size=batch_size)\n",
    "        loss_train, acc_train = common_model.evaluate(common_x_train, common_y_train,\n",
    "                                                  verbose=0, batch_size=batch_size)\n",
    "        if verbose > 0:\n",
    "            print('Loss:', loss_val, 'Acc:', acc_val)\n",
    "    if return_model:\n",
    "        return common_model\n",
    "    else:\n",
    "        return (loss_train, acc_train), (loss_val, acc_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bandwidth network\n",
      "Train on 1226 samples, validate on 217 samples\n",
      "Epoch 1/50\n",
      "1226/1226 [==============================] - 11s - loss: 2.2326 - acc: 0.4698 - val_loss: 3.4819 - val_acc: 0.4747\n",
      "Epoch 2/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.8590 - acc: 0.4478 - val_loss: 3.1032 - val_acc: 0.4747\n",
      "Epoch 3/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.7412 - acc: 0.4869 - val_loss: 3.0496 - val_acc: 0.4747\n",
      "Epoch 4/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.6365 - acc: 0.4690 - val_loss: 3.0469 - val_acc: 0.4747\n",
      "Epoch 5/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.4977 - acc: 0.4984 - val_loss: 2.7926 - val_acc: 0.4747\n",
      "Epoch 6/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.3474 - acc: 0.5179 - val_loss: 2.5532 - val_acc: 0.4747\n",
      "Epoch 7/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.2615 - acc: 0.5318 - val_loss: 2.2736 - val_acc: 0.4747\n",
      "Epoch 8/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.2209 - acc: 0.5237 - val_loss: 2.0277 - val_acc: 0.4747\n",
      "Epoch 9/50\n",
      "1226/1226 [==============================] - 0s - loss: 1.0739 - acc: 0.5636 - val_loss: 1.9372 - val_acc: 0.4747\n",
      "Epoch 10/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.9552 - acc: 0.5946 - val_loss: 1.7022 - val_acc: 0.4747\n",
      "Epoch 11/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.8937 - acc: 0.5954 - val_loss: 1.5985 - val_acc: 0.4747\n",
      "Epoch 12/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.7838 - acc: 0.6533 - val_loss: 1.2045 - val_acc: 0.5023\n",
      "Epoch 13/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.7616 - acc: 0.6542 - val_loss: 1.0365 - val_acc: 0.5023\n",
      "Epoch 14/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.6387 - acc: 0.6860 - val_loss: 0.7466 - val_acc: 0.5668\n",
      "Epoch 15/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5938 - acc: 0.7153 - val_loss: 0.8084 - val_acc: 0.5576\n",
      "Epoch 16/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5566 - acc: 0.7096 - val_loss: 0.5397 - val_acc: 0.6866\n",
      "Epoch 17/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5337 - acc: 0.7365 - val_loss: 0.5000 - val_acc: 0.7373\n",
      "Epoch 18/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4967 - acc: 0.7333 - val_loss: 0.5237 - val_acc: 0.6866\n",
      "Epoch 19/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4667 - acc: 0.7529 - val_loss: 0.4455 - val_acc: 0.7604\n",
      "Epoch 20/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4618 - acc: 0.7749 - val_loss: 0.4290 - val_acc: 0.7788\n",
      "Epoch 21/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4643 - acc: 0.7577 - val_loss: 0.4338 - val_acc: 0.7788\n",
      "Epoch 22/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4166 - acc: 0.8059 - val_loss: 0.5117 - val_acc: 0.7189\n",
      "Epoch 23/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4126 - acc: 0.8197 - val_loss: 0.5698 - val_acc: 0.7051\n",
      "Epoch 24/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3974 - acc: 0.8263 - val_loss: 0.3739 - val_acc: 0.8157\n",
      "Epoch 25/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3593 - acc: 0.8263 - val_loss: 0.3748 - val_acc: 0.8111\n",
      "Epoch 26/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3797 - acc: 0.8222 - val_loss: 0.3443 - val_acc: 0.8479\n",
      "Epoch 27/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3625 - acc: 0.8418 - val_loss: 0.4388 - val_acc: 0.7834\n",
      "Epoch 28/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3334 - acc: 0.8507 - val_loss: 0.4770 - val_acc: 0.7834\n",
      "Epoch 29/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3434 - acc: 0.8426 - val_loss: 0.3712 - val_acc: 0.8203\n",
      "Epoch 30/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3366 - acc: 0.8361 - val_loss: 0.2881 - val_acc: 0.8756\n",
      "Epoch 31/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3383 - acc: 0.8450 - val_loss: 0.3681 - val_acc: 0.8525\n",
      "Epoch 32/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3383 - acc: 0.8434 - val_loss: 0.4757 - val_acc: 0.7604\n",
      "Epoch 33/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2975 - acc: 0.8646 - val_loss: 0.3686 - val_acc: 0.8433\n",
      "Epoch 34/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3023 - acc: 0.8711 - val_loss: 0.3210 - val_acc: 0.8756\n",
      "Epoch 35/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3005 - acc: 0.8662 - val_loss: 0.3605 - val_acc: 0.8203\n",
      "Epoch 36/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2694 - acc: 0.8695 - val_loss: 0.3446 - val_acc: 0.8664\n",
      "Epoch 37/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2730 - acc: 0.8817 - val_loss: 0.3627 - val_acc: 0.8249\n",
      "Epoch 38/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2628 - acc: 0.8744 - val_loss: 0.3305 - val_acc: 0.8525\n",
      "Epoch 39/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2474 - acc: 0.8834 - val_loss: 0.2720 - val_acc: 0.8756\n",
      "Epoch 40/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2480 - acc: 0.8907 - val_loss: 0.3129 - val_acc: 0.8710\n",
      "Epoch 41/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2413 - acc: 0.8989 - val_loss: 0.3590 - val_acc: 0.8203\n",
      "Epoch 42/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2398 - acc: 0.8948 - val_loss: 0.2897 - val_acc: 0.8710\n",
      "Epoch 43/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2320 - acc: 0.9005 - val_loss: 0.2956 - val_acc: 0.8664\n",
      "Epoch 44/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2236 - acc: 0.8989 - val_loss: 0.2805 - val_acc: 0.8802\n",
      "Epoch 45/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2233 - acc: 0.9054 - val_loss: 0.3042 - val_acc: 0.8710\n",
      "Epoch 46/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2168 - acc: 0.9095 - val_loss: 0.2946 - val_acc: 0.8894\n",
      "Epoch 47/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2268 - acc: 0.8980 - val_loss: 0.3149 - val_acc: 0.8571\n",
      "Epoch 48/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2364 - acc: 0.9005 - val_loss: 0.3517 - val_acc: 0.8525\n",
      "Epoch 49/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2337 - acc: 0.9013 - val_loss: 0.2944 - val_acc: 0.8710\n",
      "Epoch 50/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2131 - acc: 0.9103 - val_loss: 0.2548 - val_acc: 0.8848\n",
      "Loading model\n",
      "Val/Train Loss: 0.199417740292/0.169184086593 Val/Train Acc: 0.894409937888/0.932085932086\n",
      "Training image network\n",
      "Train on 1226 samples, validate on 217 samples\n",
      "Epoch 1/50\n",
      "1226/1226 [==============================] - 1s - loss: 0.8318 - acc: 0.5196 - val_loss: 0.8413 - val_acc: 0.5438\n",
      "Epoch 2/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.6330 - acc: 0.6313 - val_loss: 0.7641 - val_acc: 0.6129\n",
      "Epoch 3/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.6198 - acc: 0.6533 - val_loss: 0.7894 - val_acc: 0.5806\n",
      "Epoch 4/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5752 - acc: 0.6819 - val_loss: 0.7077 - val_acc: 0.6221\n",
      "Epoch 5/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5651 - acc: 0.6941 - val_loss: 0.7190 - val_acc: 0.5899\n",
      "Epoch 6/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5735 - acc: 0.6958 - val_loss: 0.6988 - val_acc: 0.6175\n",
      "Epoch 7/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5618 - acc: 0.7072 - val_loss: 0.6624 - val_acc: 0.6267\n",
      "Epoch 8/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5482 - acc: 0.7219 - val_loss: 0.6501 - val_acc: 0.6359\n",
      "Epoch 9/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5315 - acc: 0.7333 - val_loss: 0.5755 - val_acc: 0.6912\n",
      "Epoch 10/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5420 - acc: 0.7268 - val_loss: 0.5816 - val_acc: 0.6866\n",
      "Epoch 11/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5012 - acc: 0.7602 - val_loss: 0.6205 - val_acc: 0.6636\n",
      "Epoch 12/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.5031 - acc: 0.7610 - val_loss: 0.5517 - val_acc: 0.7143\n",
      "Epoch 13/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4725 - acc: 0.7716 - val_loss: 0.5002 - val_acc: 0.7742\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226/1226 [==============================] - 0s - loss: 0.4181 - acc: 0.8140 - val_loss: 0.3897 - val_acc: 0.8295\n",
      "Epoch 15/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.4048 - acc: 0.8222 - val_loss: 0.3705 - val_acc: 0.8203\n",
      "Epoch 16/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3757 - acc: 0.8377 - val_loss: 0.4079 - val_acc: 0.8111\n",
      "Epoch 17/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3892 - acc: 0.8328 - val_loss: 0.3322 - val_acc: 0.8618\n",
      "Epoch 18/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3387 - acc: 0.8670 - val_loss: 0.4418 - val_acc: 0.7926\n",
      "Epoch 19/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3346 - acc: 0.8564 - val_loss: 0.3179 - val_acc: 0.8756\n",
      "Epoch 20/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3301 - acc: 0.8622 - val_loss: 0.3317 - val_acc: 0.8618\n",
      "Epoch 21/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3091 - acc: 0.8768 - val_loss: 0.3372 - val_acc: 0.8618\n",
      "Epoch 22/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3247 - acc: 0.8646 - val_loss: 0.3014 - val_acc: 0.8802\n",
      "Epoch 23/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3018 - acc: 0.8719 - val_loss: 0.3617 - val_acc: 0.8203\n",
      "Epoch 24/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2822 - acc: 0.8760 - val_loss: 0.3800 - val_acc: 0.8341\n",
      "Epoch 25/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2749 - acc: 0.8711 - val_loss: 0.2942 - val_acc: 0.8848\n",
      "Epoch 26/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.3035 - acc: 0.8858 - val_loss: 0.2858 - val_acc: 0.8710\n",
      "Epoch 27/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2800 - acc: 0.8834 - val_loss: 0.3164 - val_acc: 0.8802\n",
      "Epoch 28/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2790 - acc: 0.8752 - val_loss: 0.2988 - val_acc: 0.8756\n",
      "Epoch 29/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2646 - acc: 0.8931 - val_loss: 0.3270 - val_acc: 0.8710\n",
      "Epoch 30/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2513 - acc: 0.8948 - val_loss: 0.3406 - val_acc: 0.8525\n",
      "Epoch 31/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2778 - acc: 0.8858 - val_loss: 0.2758 - val_acc: 0.8802\n",
      "Epoch 32/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2399 - acc: 0.8883 - val_loss: 0.2988 - val_acc: 0.8940\n",
      "Epoch 33/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2350 - acc: 0.8972 - val_loss: 0.2794 - val_acc: 0.8940\n",
      "Epoch 34/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2474 - acc: 0.8948 - val_loss: 0.3086 - val_acc: 0.8848\n",
      "Epoch 35/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2309 - acc: 0.9062 - val_loss: 0.3480 - val_acc: 0.8571\n",
      "Epoch 36/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2513 - acc: 0.8801 - val_loss: 0.3144 - val_acc: 0.8571\n",
      "Epoch 37/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2353 - acc: 0.9029 - val_loss: 0.2745 - val_acc: 0.8986\n",
      "Epoch 38/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2226 - acc: 0.9111 - val_loss: 0.3067 - val_acc: 0.8986\n",
      "Epoch 39/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2049 - acc: 0.9217 - val_loss: 0.2554 - val_acc: 0.8986\n",
      "Epoch 40/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2303 - acc: 0.9054 - val_loss: 0.2566 - val_acc: 0.9078\n",
      "Epoch 41/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2272 - acc: 0.9070 - val_loss: 0.4028 - val_acc: 0.8157\n",
      "Epoch 42/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2020 - acc: 0.9144 - val_loss: 0.2672 - val_acc: 0.9078\n",
      "Epoch 43/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2272 - acc: 0.8989 - val_loss: 0.2523 - val_acc: 0.8986\n",
      "Epoch 44/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2046 - acc: 0.9062 - val_loss: 0.2791 - val_acc: 0.8986\n",
      "Epoch 45/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.1968 - acc: 0.9176 - val_loss: 0.3233 - val_acc: 0.8894\n",
      "Epoch 46/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.1863 - acc: 0.9258 - val_loss: 0.3247 - val_acc: 0.8756\n",
      "Epoch 47/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2051 - acc: 0.9103 - val_loss: 0.2356 - val_acc: 0.9032\n",
      "Epoch 48/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.2071 - acc: 0.9062 - val_loss: 0.2669 - val_acc: 0.8802\n",
      "Epoch 49/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.1914 - acc: 0.9168 - val_loss: 0.3151 - val_acc: 0.8848\n",
      "Epoch 50/50\n",
      "1226/1226 [==============================] - 0s - loss: 0.1681 - acc: 0.9339 - val_loss: 0.2607 - val_acc: 0.9124\n",
      "Loading model\n",
      "Val/Train Loss: 7.10798005288/0.146265197297 Val/Train Acc: 0.55900621118/0.943866943867\n",
      "Training common network\n",
      "Train on 1154 samples, validate on 289 samples\n",
      "Epoch 1/50\n",
      "1154/1154 [==============================] - 2s - loss: 0.4079 - acc: 0.8198 - val_loss: 0.6948 - val_acc: 0.5121\n",
      "Epoch 2/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3988 - acc: 0.8198 - val_loss: 0.4703 - val_acc: 0.7889\n",
      "Epoch 3/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3850 - acc: 0.8276 - val_loss: 0.3089 - val_acc: 0.8962\n",
      "Epoch 4/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3257 - acc: 0.8562 - val_loss: 0.4369 - val_acc: 0.7751\n",
      "Epoch 5/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.6045 - acc: 0.6499 - val_loss: 0.4912 - val_acc: 0.7647\n",
      "Epoch 6/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.5959 - acc: 0.6690 - val_loss: 0.4639 - val_acc: 0.7820\n",
      "Epoch 7/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.5212 - acc: 0.7262 - val_loss: 0.5377 - val_acc: 0.7093\n",
      "Epoch 8/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.5100 - acc: 0.7392 - val_loss: 0.5875 - val_acc: 0.7059\n",
      "Epoch 9/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4722 - acc: 0.7808 - val_loss: 0.4321 - val_acc: 0.7785\n",
      "Epoch 10/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4270 - acc: 0.7868 - val_loss: 0.5238 - val_acc: 0.7059\n",
      "Epoch 11/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4812 - acc: 0.7695 - val_loss: 0.4007 - val_acc: 0.8374\n",
      "Epoch 12/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4007 - acc: 0.8102 - val_loss: 0.4107 - val_acc: 0.7958\n",
      "Epoch 13/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.5180 - acc: 0.7383 - val_loss: 0.4704 - val_acc: 0.7716\n",
      "Epoch 14/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4441 - acc: 0.7964 - val_loss: 0.3700 - val_acc: 0.8408\n",
      "Epoch 15/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4007 - acc: 0.7998 - val_loss: 0.3730 - val_acc: 0.8166\n",
      "Epoch 16/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4043 - acc: 0.8059 - val_loss: 0.3644 - val_acc: 0.8131\n",
      "Epoch 17/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3835 - acc: 0.8258 - val_loss: 0.3697 - val_acc: 0.8131\n",
      "Epoch 18/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3555 - acc: 0.8440 - val_loss: 0.3399 - val_acc: 0.8443\n",
      "Epoch 19/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3349 - acc: 0.8440 - val_loss: 0.3445 - val_acc: 0.8408\n",
      "Epoch 20/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3559 - acc: 0.8414 - val_loss: 0.3154 - val_acc: 0.8651\n",
      "Epoch 21/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3466 - acc: 0.8388 - val_loss: 0.3396 - val_acc: 0.8408\n",
      "Epoch 22/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3347 - acc: 0.8458 - val_loss: 0.3549 - val_acc: 0.8581\n",
      "Epoch 23/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3699 - acc: 0.8336 - val_loss: 0.3304 - val_acc: 0.8339\n",
      "Epoch 24/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3650 - acc: 0.8406 - val_loss: 0.3479 - val_acc: 0.8201\n",
      "Epoch 25/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3423 - acc: 0.8475 - val_loss: 0.3348 - val_acc: 0.8443\n",
      "Epoch 26/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3198 - acc: 0.8596 - val_loss: 0.3818 - val_acc: 0.8131\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1154/1154 [==============================] - 1s - loss: 0.3309 - acc: 0.8518 - val_loss: 0.4593 - val_acc: 0.7751\n",
      "Epoch 28/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3358 - acc: 0.8484 - val_loss: 0.3307 - val_acc: 0.8478\n",
      "Epoch 29/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3614 - acc: 0.8362 - val_loss: 0.3125 - val_acc: 0.8651\n",
      "Epoch 30/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3491 - acc: 0.8414 - val_loss: 0.4784 - val_acc: 0.7543\n",
      "Epoch 31/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3422 - acc: 0.8380 - val_loss: 0.3568 - val_acc: 0.8581\n",
      "Epoch 32/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.4112 - acc: 0.8085 - val_loss: 0.3064 - val_acc: 0.8581\n",
      "Epoch 33/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3638 - acc: 0.8328 - val_loss: 0.3226 - val_acc: 0.8685\n",
      "Epoch 34/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3172 - acc: 0.8484 - val_loss: 0.3087 - val_acc: 0.8893\n",
      "Epoch 35/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3314 - acc: 0.8588 - val_loss: 0.2993 - val_acc: 0.8754\n",
      "Epoch 36/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2948 - acc: 0.8622 - val_loss: 0.3548 - val_acc: 0.8408\n",
      "Epoch 37/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3269 - acc: 0.8501 - val_loss: 0.3126 - val_acc: 0.8581\n",
      "Epoch 38/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2941 - acc: 0.8718 - val_loss: 0.4266 - val_acc: 0.7855\n",
      "Epoch 39/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2875 - acc: 0.8821 - val_loss: 0.3120 - val_acc: 0.8616\n",
      "Epoch 40/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2814 - acc: 0.8813 - val_loss: 0.3309 - val_acc: 0.8824\n",
      "Epoch 41/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.3053 - acc: 0.8666 - val_loss: 0.2920 - val_acc: 0.8789\n",
      "Epoch 42/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2871 - acc: 0.8683 - val_loss: 0.3162 - val_acc: 0.8547\n",
      "Epoch 43/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2839 - acc: 0.8769 - val_loss: 0.3243 - val_acc: 0.8789\n",
      "Epoch 44/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2788 - acc: 0.8804 - val_loss: 0.2909 - val_acc: 0.8685\n",
      "Epoch 45/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2781 - acc: 0.8709 - val_loss: 0.4221 - val_acc: 0.8097\n",
      "Epoch 46/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2973 - acc: 0.8674 - val_loss: 0.3396 - val_acc: 0.8512\n",
      "Epoch 47/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2790 - acc: 0.8908 - val_loss: 0.2792 - val_acc: 0.8651\n",
      "Epoch 48/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2660 - acc: 0.8951 - val_loss: 0.2946 - val_acc: 0.8512\n",
      "Epoch 49/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2768 - acc: 0.8700 - val_loss: 0.3078 - val_acc: 0.8581\n",
      "Epoch 50/50\n",
      "1154/1154 [==============================] - 1s - loss: 0.2394 - acc: 0.8882 - val_loss: 0.4243 - val_acc: 0.8028\n",
      "Loading model\n",
      "Loss: 0.252081294608 Acc: 0.88198757764\n"
     ]
    }
   ],
   "source": [
    "# Best parameters i got are\n",
    "# epochs : 250\n",
    "# learning rate : 8e-5\n",
    "# batch size : 32\n",
    "# CARE: The image model is overfits with parameters used here\n",
    "common_model = train_models((X_angles, y_train, X_b, X_images), 5e-04, 32, 50, 1, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test dataset\n"
     ]
    }
   ],
   "source": [
    "if predict_submission:\n",
    "    print('Reading test dataset')\n",
    "    #test = pd.read_json(\"../ShipIceberg/Data/test.json\")\n",
    "    import json\n",
    "    with open('../ShipIceberg/Data/test.json', 'r') as f:\n",
    "        test = json.load(f)\n",
    "        test=pd.DataFrame(test)\n",
    "    test.inc_angle = test.inc_angle.replace('na', 0)\n",
    "    test.inc_angle = test.inc_angle.astype(float).fillna(0.0)\n",
    "    y_fin, X_angle_fin, X_fin_b, X_fin_img = create_dataset(test, False)\n",
    "    print('X shape:', X_fin_img.shape)\n",
    "    print('X angle shape:', X_angle_fin.shape)\n",
    "    print('Predicting')\n",
    "    prediction = common_model.predict([X_fin_b, X_fin_img, X_angle_fin], verbose=1, batch_size=32)\n",
    "    print('Submitting')\n",
    "    submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n",
    "\n",
    "    submission.to_csv(\"./submission.csv\", index=False)\n",
    "    print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

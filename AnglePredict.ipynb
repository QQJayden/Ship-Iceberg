{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Angle predict\n",
    "+ [Predicting Missing Incidence Angles](https://www.kaggle.com/reppic/predicting-missing-incidence-angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# train = pd.read_json(\"./Data/train.json\")\\n\\ntraining_examples = train.shape[0]\\nmissing_angles = len(train[train[\\'inc_angle\\'] == \\'na\\'])\\npercent_missing = (missing_angles/training_examples)*100\\n\\nprint(\"{0}/{1} ({2:.2f}%) of examples are missing inc_angle\".format(\\n    missing_angles, training_examples, percent_missing))\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "'''\n",
    "# train = pd.read_json(\"./Data/train.json\")\n",
    "\n",
    "training_examples = train.shape[0]\n",
    "missing_angles = len(train[train['inc_angle'] == 'na'])\n",
    "percent_missing = (missing_angles/training_examples)*100\n",
    "\n",
    "print(\"{0}/{1} ({2:.2f}%) of examples are missing inc_angle\".format(\n",
    "    missing_angles, training_examples, percent_missing))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Include the test data in our calculations: \\ntest = pd.read_json(\"./Data/test.json\")\\ntrain_no_ib = train.drop([\\'is_iceberg\\'],axis=1)\\nexamples = pd.concat([train_no_ib,test])\\n\\ninc_angles = examples[examples[\\'inc_angle\\'] != \\'na\\'][\\'inc_angle\\']\\n\\nmean = inc_angles.mean()\\nmedian = inc_angles.median()\\nmode = inc_angles.astype(np.double).round(1).mode()[0] # round to the nearest tenth for mode\\nprint(\"Mean: {0}\\nMedian: {1}\\nMode: {2}\".format(mean,median,mode))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Include the test data in our calculations: \n",
    "test = pd.read_json(\"./Data/test.json\")\n",
    "train_no_ib = train.drop(['is_iceberg'],axis=1)\n",
    "examples = pd.concat([train_no_ib,test])\n",
    "\n",
    "inc_angles = examples[examples['inc_angle'] != 'na']['inc_angle']\n",
    "\n",
    "mean = inc_angles.mean()\n",
    "median = inc_angles.median()\n",
    "mode = inc_angles.astype(np.double).round(1).mode()[0] # round to the nearest tenth for mode\n",
    "print(\"Mean: {0}\\nMedian: {1}\\nMode: {2}\".format(mean,median,mode))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninc_angles_train, inc_angles_valid = train_test_split(inc_angles, random_state=1, train_size=0.8, test_size=0.2)\\n\\nones = np.ones(inc_angles_valid.shape[0])\\nmean_mae = mean_absolute_error(ones*inc_angles_train.mean(), inc_angles_valid)\\nmedian_mae = mean_absolute_error(ones*inc_angles_train.median(), inc_angles_valid)\\nmode_mae = mean_absolute_error(ones*inc_angles_train.astype(np.double).round(1).mode()[0], inc_angles_valid)\\n\\nprint(\"Mean Error: {0}\\nMedian Error: {1}\\nMode Error: {2}\".format(mean_mae,median_mae,mode_mae))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "'''\n",
    "inc_angles_train, inc_angles_valid = train_test_split(inc_angles, random_state=1, train_size=0.8, test_size=0.2)\n",
    "\n",
    "ones = np.ones(inc_angles_valid.shape[0])\n",
    "mean_mae = mean_absolute_error(ones*inc_angles_train.mean(), inc_angles_valid)\n",
    "median_mae = mean_absolute_error(ones*inc_angles_train.median(), inc_angles_valid)\n",
    "mode_mae = mean_absolute_error(ones*inc_angles_train.astype(np.double).round(1).mode()[0], inc_angles_valid)\n",
    "\n",
    "print(\"Mean Error: {0}\\nMedian Error: {1}\\nMode Error: {2}\".format(mean_mae,median_mae,mode_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_out = train.copy()\\n\\nmin_var = median_mae*-0.5\\nmax_var = median_mae*0.5\\n\\ntrain_out['inc_angle'] = [(median + uniform(min_var,max_var)) if angle == 'na' \\n                          else angle \\n                          for angle in train_out['inc_angle']]\\n\\ntrain_out.to_json('train_median_fill.json')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import uniform\n",
    "'''\n",
    "train_out = train.copy()\n",
    "\n",
    "min_var = median_mae*-0.5\n",
    "max_var = median_mae*0.5\n",
    "\n",
    "train_out['inc_angle'] = [(median + uniform(min_var,max_var)) if angle == 'na' \n",
    "                          else angle \n",
    "                          for angle in train_out['inc_angle']]\n",
    "\n",
    "train_out.to_json('train_median_fill.json')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Input,Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D, Reshape, Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "def model(dropout=0.1, regularization=0.00005):\n",
    "\n",
    "    x_input = Input(shape=(75,75,2,1,)) \n",
    "\n",
    "    # Layer 1\n",
    "    x = Conv3D(96, kernel_size=(5, 5, 2),activation='relu',input_shape=(75, 75, 2,1), kernel_regularizer=l2(regularization))(x_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Reshape((35,35,96))(x)\n",
    "\n",
    "    # Layer 2\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    # Layer 3\n",
    "    x = Conv2D(256, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(dropout+0.1)(x)\n",
    "    \n",
    "    # Layer 4\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Layer 5\n",
    "    x = Dense(768, kernel_regularizer=l2(regularization))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout+0.1)(x)\n",
    "    \n",
    "    # Layer 6\n",
    "    x = Dense(384, kernel_regularizer=l2(regularization))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout+0.1)(x)\n",
    "    \n",
    "    # Linear Output Layer\n",
    "    y_ = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=y_)\n",
    "    adam_otim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam_otim, metrics=['mae'])\n",
    "    \n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_json(\"./Data/train.json\")\n",
    "# test = pd.read_json(\"./Data/test.json\")\n",
    "\n",
    "def load_train_data():\n",
    "    train = pd.read_json(\"./Data/train.json\")\n",
    "    test = pd.read_json(\"./Data/test.json\")\n",
    "    \n",
    "    train = train.drop(['is_iceberg'],axis=1)\n",
    "    train = pd.concat([train,test])\n",
    "    train = train[train['inc_angle'] != 'na']\n",
    "    \n",
    "    band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "    band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "    bands = np.concatenate([band_1[:, :, :, np.newaxis], band_2[:, :, :, np.newaxis]], axis=-1)\n",
    "    bands = bands.reshape((-1, 75, 75, 2, 1))\n",
    "    \n",
    "    angles = train[\"inc_angle\"]\n",
    "    \n",
    "    return train_test_split(bands, angles, random_state=1, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7916 samples, validate on 1979 samples\n",
      "Epoch 1/25\n",
      "7916/7916 [==============================] - 28s - loss: 448.5834 - mean_absolute_error: 17.5026 - val_loss: 53.1274 - val_mean_absolute_error: 5.3332\n",
      "Epoch 2/25\n",
      "7916/7916 [==============================] - 25s - loss: 23.8202 - mean_absolute_error: 3.9174 - val_loss: 18.9583 - val_mean_absolute_error: 3.4452\n",
      "Epoch 3/25\n",
      "7916/7916 [==============================] - 26s - loss: 20.7921 - mean_absolute_error: 3.6693 - val_loss: 135.1869 - val_mean_absolute_error: 10.0852\n",
      "Epoch 4/25\n",
      "7916/7916 [==============================] - 26s - loss: 19.5839 - mean_absolute_error: 3.5627 - val_loss: 15.8980 - val_mean_absolute_error: 3.2251\n",
      "Epoch 5/25\n",
      "7916/7916 [==============================] - 26s - loss: 19.1547 - mean_absolute_error: 3.5341 - val_loss: 15.3061 - val_mean_absolute_error: 3.1831\n",
      "Epoch 6/25\n",
      "7916/7916 [==============================] - 26s - loss: 18.7568 - mean_absolute_error: 3.4802 - val_loss: 13.7097 - val_mean_absolute_error: 2.9456\n",
      "Epoch 7/25\n",
      "7916/7916 [==============================] - 26s - loss: 18.2536 - mean_absolute_error: 3.4394 - val_loss: 16.4131 - val_mean_absolute_error: 3.3125\n",
      "Epoch 8/25\n",
      "7916/7916 [==============================] - 26s - loss: 18.4832 - mean_absolute_error: 3.4464 - val_loss: 18.6595 - val_mean_absolute_error: 3.6642\n",
      "Epoch 9/25\n",
      "7916/7916 [==============================] - 26s - loss: 18.7188 - mean_absolute_error: 3.4728 - val_loss: 14.3665 - val_mean_absolute_error: 3.0611\n",
      "Epoch 10/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.8598 - mean_absolute_error: 3.3996 - val_loss: 15.1275 - val_mean_absolute_error: 3.1477\n",
      "Epoch 11/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.7502 - mean_absolute_error: 3.4000 - val_loss: 14.4730 - val_mean_absolute_error: 2.9825\n",
      "Epoch 12/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.9801 - mean_absolute_error: 3.4149 - val_loss: 14.6178 - val_mean_absolute_error: 3.0936\n",
      "Epoch 13/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.7166 - mean_absolute_error: 3.4013 - val_loss: 13.2398 - val_mean_absolute_error: 2.8761\n",
      "Epoch 14/25\n",
      "7916/7916 [==============================] - 25s - loss: 17.5207 - mean_absolute_error: 3.3801 - val_loss: 15.6336 - val_mean_absolute_error: 3.2133\n",
      "Epoch 15/25\n",
      "7916/7916 [==============================] - 25s - loss: 17.6297 - mean_absolute_error: 3.3787 - val_loss: 15.1239 - val_mean_absolute_error: 3.1231\n",
      "Epoch 16/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.4980 - mean_absolute_error: 3.3697 - val_loss: 14.3682 - val_mean_absolute_error: 3.0760\n",
      "Epoch 17/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.9883 - mean_absolute_error: 3.3033 - val_loss: 14.2524 - val_mean_absolute_error: 2.9932\n",
      "Epoch 18/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.0585 - mean_absolute_error: 3.3030 - val_loss: 13.3618 - val_mean_absolute_error: 2.8434\n",
      "Epoch 19/25\n",
      "7916/7916 [==============================] - 26s - loss: 17.1128 - mean_absolute_error: 3.3185 - val_loss: 17.7547 - val_mean_absolute_error: 3.3197\n",
      "Epoch 20/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.8695 - mean_absolute_error: 3.2982 - val_loss: 13.5909 - val_mean_absolute_error: 2.9584\n",
      "Epoch 21/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.4276 - mean_absolute_error: 3.2387 - val_loss: 14.4101 - val_mean_absolute_error: 2.9500\n",
      "Epoch 22/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.5862 - mean_absolute_error: 3.2591 - val_loss: 16.2048 - val_mean_absolute_error: 3.2871\n",
      "Epoch 23/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.1242 - mean_absolute_error: 3.1880 - val_loss: 13.0749 - val_mean_absolute_error: 2.8361\n",
      "Epoch 24/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.2326 - mean_absolute_error: 3.2230 - val_loss: 16.7051 - val_mean_absolute_error: 3.3038\n",
      "Epoch 25/25\n",
      "7916/7916 [==============================] - 26s - loss: 16.2732 - mean_absolute_error: 3.2306 - val_loss: 14.5756 - val_mean_absolute_error: 3.0384\n"
     ]
    }
   ],
   "source": [
    "m = model()\n",
    "x_train, x_valid, y_train, y_valid = load_train_data()\n",
    "weights_file = './model/inc_angle_weights_pretrained.hdf5'\n",
    "\n",
    "TRAIN_FROM_SCRATCH = True\n",
    "\n",
    "if TRAIN_FROM_SCRATCH:\n",
    "    checkpoint = ModelCheckpoint(weights_file, save_best_only=True)\n",
    "    m.fit(x_train, y_train, batch_size=32, epochs=25, verbose=1,\n",
    "              validation_data=(x_valid, y_valid),\n",
    "              callbacks=[checkpoint])\n",
    "else:\n",
    "    m.load_weights(filepath=weights_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952/1979 [============================>.] - ETA: 0sModel Error: 3.0383988267559543\n"
     ]
    }
   ],
   "source": [
    "predicted_angles = m.predict(x_valid, verbose=1)\n",
    "model_mae = mean_absolute_error(predicted_angles, y_valid)\n",
    "print('Model Error: {0}'.format(model_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_inc_angle(ex, model):\n",
    "    band_1 = np.array([np.array(ex[\"band_1\"]).astype(np.float32).reshape(75, 75)])\n",
    "    band_2 = np.array([np.array(ex[\"band_2\"]).astype(np.float32).reshape(75, 75)])\n",
    "    bands = np.concatenate([band_1[:, :, :, np.newaxis], band_2[:, :, :, np.newaxis]], axis=-1)\n",
    "    bands = bands.reshape((1, 75, 75, 2, 1))\n",
    "    inc_angle = model.predict(bands)\n",
    "    return inc_angle.reshape(1)[0]\n",
    "    \n",
    "train = pd.read_json(\"./Data/train.json\")\n",
    "train_out_model = train.copy()\n",
    "\n",
    "train_out_model['inc_angle'] = [predict_inc_angle(ex,m) if ex['inc_angle'] == 'na' \n",
    "                          else ex['inc_angle'] \n",
    "                          for _,ex in train_out_model.iterrows()]\n",
    "\n",
    "# train_out_model.to_json('./Data/train_model_fill.json')\n",
    "train_out_model.to_json('./Data/train_model_fill_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_out_model['inc_angle'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

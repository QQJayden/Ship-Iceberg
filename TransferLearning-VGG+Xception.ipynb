{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning VGG16+Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.json\n",
      "train.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#import pylab\n",
    "#plt.rcParams['figure.figsize'] = 10, 10\n",
    "#%matplotlib inline\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../ShipIceberg/Data\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../ShipIceberg/Data/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "\n",
    "# 一直cannot resolve memory block\n",
    "test = pd.read_json(\"../ShipIceberg/Data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "\n",
    "X_band_3 = np.zeros((1604,75,75))\n",
    "for i in range(0,1604):\n",
    "    subt = abs(X_band_1[i]-X_band_2[i])\n",
    "    W1 = subt/subt.max()\n",
    "    W2=1-W1\n",
    "    X_band_3[i]=W1 * X_band_1[i]+W2 * X_band_2[i]\n",
    "    \n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "\n",
    "X_band_test_3 = np.zeros((8424,75,75))\n",
    "for i in range(0,8424):\n",
    "    subt = abs(X_band_test_1[i]-X_band_test_2[i])\n",
    "    W1 = subt/subt.max()\n",
    "    W2=1-W1\n",
    "    X_band_test_3[i]=W1 * X_band_test_1[i]+W2 * X_band_test_2[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "# del train;del test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "   #es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "   es = EarlyStopping('val_loss', patience=20, mode=\"min\")\n",
    "   msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "   return [es, msave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "#     x = base_model.get_layer('block5_pool').output\n",
    "    x= base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     base_model2 = Xception(weights='imagenet', include_top=False, input_tensor = base_model.input,\n",
    "#                  input_shape=X_train.shape[1:], classes=1)\n",
    "    x2 = base_model2.output\n",
    "    x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "    merge_one = concatenate([x, x2, angle_layer])\n",
    "    \n",
    "    #     merge_one = x\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "#     merge_one = Dense(1024, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one) # 参数原来0.3\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "#     merge_one = Dense(256, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "\n",
    "#     merge_one = Dropout(0.6)(merge_one)\n",
    "#     predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"./model/%s_aug_vgg_xception_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "#                 steps_per_epoch=24,\n",
    "                steps_per_epoch=len(X_train_cv)//batch_size,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 33s - loss: 0.7439 - acc: 0.5215 - val_loss: 1.1872 - val_acc: 0.5308\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 10s - loss: 0.6813 - acc: 0.5935 - val_loss: 1.0257 - val_acc: 0.5308\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 10s - loss: 0.6403 - acc: 0.6088 - val_loss: 0.8350 - val_acc: 0.5103\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 10s - loss: 0.6095 - acc: 0.6456 - val_loss: 0.7295 - val_acc: 0.4841\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 10s - loss: 0.5770 - acc: 0.6794 - val_loss: 0.7116 - val_acc: 0.5720\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 10s - loss: 0.5369 - acc: 0.7253 - val_loss: 0.7066 - val_acc: 0.5794\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 10s - loss: 0.5382 - acc: 0.7326 - val_loss: 0.6910 - val_acc: 0.5944\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 9s - loss: 0.4821 - acc: 0.7539 - val_loss: 0.7453 - val_acc: 0.6019\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 9s - loss: 0.4631 - acc: 0.7846 - val_loss: 0.7251 - val_acc: 0.6355\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 10s - loss: 0.4626 - acc: 0.7636 - val_loss: 0.6318 - val_acc: 0.6897\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 10s - loss: 0.4291 - acc: 0.7975 - val_loss: 0.5189 - val_acc: 0.7290\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 10s - loss: 0.4333 - acc: 0.8061 - val_loss: 0.4695 - val_acc: 0.7495\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 10s - loss: 0.3732 - acc: 0.8362 - val_loss: 0.4439 - val_acc: 0.7607\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 10s - loss: 0.3581 - acc: 0.8338 - val_loss: 0.4039 - val_acc: 0.7963\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 10s - loss: 0.3682 - acc: 0.8225 - val_loss: 0.3279 - val_acc: 0.8542\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 9s - loss: 0.3689 - acc: 0.8372 - val_loss: 0.3571 - val_acc: 0.8393\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 10s - loss: 0.3148 - acc: 0.8716 - val_loss: 0.3163 - val_acc: 0.8598\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 9s - loss: 0.3294 - acc: 0.8486 - val_loss: 0.3327 - val_acc: 0.8561\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 10s - loss: 0.3283 - acc: 0.8559 - val_loss: 0.2959 - val_acc: 0.8654\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 9s - loss: 0.3417 - acc: 0.8514 - val_loss: 0.3012 - val_acc: 0.8673\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 10s - loss: 0.2957 - acc: 0.8719 - val_loss: 0.2677 - val_acc: 0.8729\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 10s - loss: 0.2847 - acc: 0.8755 - val_loss: 0.2529 - val_acc: 0.8897\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 11s - loss: 0.2704 - acc: 0.8764 - val_loss: 0.2499 - val_acc: 0.8935\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 9s - loss: 0.2810 - acc: 0.8719 - val_loss: 0.2535 - val_acc: 0.8897\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 9s - loss: 0.2725 - acc: 0.8827 - val_loss: 0.2632 - val_acc: 0.8785\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 10s - loss: 0.2937 - acc: 0.8819 - val_loss: 0.2460 - val_acc: 0.8822\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 10s - loss: 0.2582 - acc: 0.8958 - val_loss: 0.2397 - val_acc: 0.8897\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 9s - loss: 0.2474 - acc: 0.8847 - val_loss: 0.2407 - val_acc: 0.8953\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 9s - loss: 0.2448 - acc: 0.9015 - val_loss: 0.2403 - val_acc: 0.8972\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 10s - loss: 0.2943 - acc: 0.8778 - val_loss: 0.2327 - val_acc: 0.8972\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 9s - loss: 0.2510 - acc: 0.8776 - val_loss: 0.2391 - val_acc: 0.8916\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 9s - loss: 0.2360 - acc: 0.8946 - val_loss: 0.2354 - val_acc: 0.8991\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 9s - loss: 0.2289 - acc: 0.9126 - val_loss: 0.2357 - val_acc: 0.8953\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 9s - loss: 0.2543 - acc: 0.8995 - val_loss: 0.2441 - val_acc: 0.8860\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 9s - loss: 0.2360 - acc: 0.9004 - val_loss: 0.2451 - val_acc: 0.8897\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 9s - loss: 0.2497 - acc: 0.8839 - val_loss: 0.2387 - val_acc: 0.8916\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 9s - loss: 0.2501 - acc: 0.8837 - val_loss: 0.2335 - val_acc: 0.8953\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 9s - loss: 0.2382 - acc: 0.9052 - val_loss: 0.2426 - val_acc: 0.8897\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 9s - loss: 0.2476 - acc: 0.9056 - val_loss: 0.2372 - val_acc: 0.8916\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 10s - loss: 0.2477 - acc: 0.9017 - val_loss: 0.2318 - val_acc: 0.8991\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 9s - loss: 0.2208 - acc: 0.8987 - val_loss: 0.2326 - val_acc: 0.8935\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 10s - loss: 0.2491 - acc: 0.8905 - val_loss: 0.2307 - val_acc: 0.8972\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 9s - loss: 0.2454 - acc: 0.8872 - val_loss: 0.2379 - val_acc: 0.8841\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 9s - loss: 0.1937 - acc: 0.9271 - val_loss: 0.2341 - val_acc: 0.8953\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 9s - loss: 0.2154 - acc: 0.9101 - val_loss: 0.2589 - val_acc: 0.8804\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 9s - loss: 0.2332 - acc: 0.9120 - val_loss: 0.2328 - val_acc: 0.8935\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 9s - loss: 0.2329 - acc: 0.9071 - val_loss: 0.2358 - val_acc: 0.8991\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 10s - loss: 0.2117 - acc: 0.9101 - val_loss: 0.2228 - val_acc: 0.8972\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 10s - loss: 0.2144 - acc: 0.9118 - val_loss: 0.2208 - val_acc: 0.9009\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 10s - loss: 0.2418 - acc: 0.8890 - val_loss: 0.2207 - val_acc: 0.8972\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 9s - loss: 0.2026 - acc: 0.9110 - val_loss: 0.2220 - val_acc: 0.9009\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 9s - loss: 0.1957 - acc: 0.9160 - val_loss: 0.2285 - val_acc: 0.9009\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 9s - loss: 0.1913 - acc: 0.9257 - val_loss: 0.2332 - val_acc: 0.9009\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 9s - loss: 0.2037 - acc: 0.9128 - val_loss: 0.2351 - val_acc: 0.8991\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 9s - loss: 0.2029 - acc: 0.9198 - val_loss: 0.2333 - val_acc: 0.8953\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 9s - loss: 0.2352 - acc: 0.9013 - val_loss: 0.2369 - val_acc: 0.8916\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 9s - loss: 0.1856 - acc: 0.9261 - val_loss: 0.2296 - val_acc: 0.8991\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 9s - loss: 0.2174 - acc: 0.9081 - val_loss: 0.2801 - val_acc: 0.8860\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 9s - loss: 0.1874 - acc: 0.9255 - val_loss: 0.2625 - val_acc: 0.8916\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 9s - loss: 0.1967 - acc: 0.9093 - val_loss: 0.2587 - val_acc: 0.8897\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 9s - loss: 0.1990 - acc: 0.9218 - val_loss: 0.2700 - val_acc: 0.8935\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 9s - loss: 0.2245 - acc: 0.9122 - val_loss: 0.2905 - val_acc: 0.8748\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 9s - loss: 0.1881 - acc: 0.9218 - val_loss: 0.4436 - val_acc: 0.8224\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 9s - loss: 0.1896 - acc: 0.9095 - val_loss: 0.3507 - val_acc: 0.8654\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 9s - loss: 0.1909 - acc: 0.9130 - val_loss: 0.3843 - val_acc: 0.8467\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 9s - loss: 0.1743 - acc: 0.9216 - val_loss: 0.4106 - val_acc: 0.8467\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 9s - loss: 0.1544 - acc: 0.9501 - val_loss: 0.4598 - val_acc: 0.8299\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 9s - loss: 0.1886 - acc: 0.9200 - val_loss: 0.4379 - val_acc: 0.8542\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 9s - loss: 0.1842 - acc: 0.9160 - val_loss: 0.2604 - val_acc: 0.8953\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 9s - loss: 0.1968 - acc: 0.9110 - val_loss: 0.2450 - val_acc: 0.8935\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 9s - loss: 0.1828 - acc: 0.9308 - val_loss: 0.2442 - val_acc: 0.8916\n",
      "Train loss: 0.158227715289\n",
      "Train accuracy: 0.932647334849\n",
      "Test loss: 0.22073347925\n",
      "Test accuracy: 0.897196263019\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 31s - loss: 0.7225 - acc: 0.5273 - val_loss: 1.5243 - val_acc: 0.5308\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 10s - loss: 0.6611 - acc: 0.6027 - val_loss: 1.3337 - val_acc: 0.5308\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 10s - loss: 0.6088 - acc: 0.6489 - val_loss: 1.0267 - val_acc: 0.5234\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 10s - loss: 0.5768 - acc: 0.6579 - val_loss: 0.7700 - val_acc: 0.4897\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 10s - loss: 0.5551 - acc: 0.6884 - val_loss: 0.6555 - val_acc: 0.6150\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 9s - loss: 0.5362 - acc: 0.7069 - val_loss: 0.7101 - val_acc: 0.5832\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 9s - loss: 0.5148 - acc: 0.7312 - val_loss: 0.6712 - val_acc: 0.6150\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 9s - loss: 0.4644 - acc: 0.7757 - val_loss: 0.6756 - val_acc: 0.6299\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 9s - loss: 0.4291 - acc: 0.7922 - val_loss: 0.6761 - val_acc: 0.6336\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 10s - loss: 0.4630 - acc: 0.7773 - val_loss: 0.5672 - val_acc: 0.6822\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 9s - loss: 0.4152 - acc: 0.8076 - val_loss: 0.5852 - val_acc: 0.6841\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 9s - loss: 0.3818 - acc: 0.8295 - val_loss: 0.5749 - val_acc: 0.6972\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 10s - loss: 0.3673 - acc: 0.8321 - val_loss: 0.5055 - val_acc: 0.7308\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 10s - loss: 0.3787 - acc: 0.8207 - val_loss: 0.4443 - val_acc: 0.7626\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 11s - loss: 0.3676 - acc: 0.8315 - val_loss: 0.3723 - val_acc: 0.8224\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 9s - loss: 0.3529 - acc: 0.8366 - val_loss: 0.3796 - val_acc: 0.8112\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 10s - loss: 0.3472 - acc: 0.8491 - val_loss: 0.3187 - val_acc: 0.8673\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 11s - loss: 0.3286 - acc: 0.8535 - val_loss: 0.3048 - val_acc: 0.8692\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 10s - loss: 0.3256 - acc: 0.8569 - val_loss: 0.2892 - val_acc: 0.8748\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 11s - loss: 0.3130 - acc: 0.8626 - val_loss: 0.2790 - val_acc: 0.8785\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 10s - loss: 0.2924 - acc: 0.8659 - val_loss: 0.2742 - val_acc: 0.8804\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 10s - loss: 0.3221 - acc: 0.8592 - val_loss: 0.2681 - val_acc: 0.8841\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 10s - loss: 0.2889 - acc: 0.8776 - val_loss: 0.2659 - val_acc: 0.8860\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 10s - loss: 0.3113 - acc: 0.8534 - val_loss: 0.2559 - val_acc: 0.8916\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 9s - loss: 0.3261 - acc: 0.8571 - val_loss: 0.2564 - val_acc: 0.8935\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 9s - loss: 0.2791 - acc: 0.8682 - val_loss: 0.2622 - val_acc: 0.8860\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 9s - loss: 0.2802 - acc: 0.8743 - val_loss: 0.2606 - val_acc: 0.8916\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 11s - loss: 0.2820 - acc: 0.8727 - val_loss: 0.2480 - val_acc: 0.8953\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 11s - loss: 0.2937 - acc: 0.8579 - val_loss: 0.2426 - val_acc: 0.8991\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 11s - loss: 0.2617 - acc: 0.8981 - val_loss: 0.2301 - val_acc: 0.9047\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 11s - loss: 0.2725 - acc: 0.8796 - val_loss: 0.2290 - val_acc: 0.8991\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 11s - loss: 0.2625 - acc: 0.8878 - val_loss: 0.2260 - val_acc: 0.9103\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 9s - loss: 0.2961 - acc: 0.8819 - val_loss: 0.2266 - val_acc: 0.9065\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 9s - loss: 0.2490 - acc: 0.8929 - val_loss: 0.2272 - val_acc: 0.9009\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 9s - loss: 0.2750 - acc: 0.8711 - val_loss: 0.2308 - val_acc: 0.9009\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 10s - loss: 0.2511 - acc: 0.8784 - val_loss: 0.2252 - val_acc: 0.9065\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 10s - loss: 0.2559 - acc: 0.8823 - val_loss: 0.2209 - val_acc: 0.9028\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 11s - loss: 0.2517 - acc: 0.8966 - val_loss: 0.2192 - val_acc: 0.9084\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 11s - loss: 0.2439 - acc: 0.8981 - val_loss: 0.2188 - val_acc: 0.9140\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 9s - loss: 0.2333 - acc: 0.9017 - val_loss: 0.2270 - val_acc: 0.9084\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 9s - loss: 0.2266 - acc: 0.8952 - val_loss: 0.2196 - val_acc: 0.9178\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 9s - loss: 0.2460 - acc: 0.8954 - val_loss: 0.2279 - val_acc: 0.9065\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 9s - loss: 0.2230 - acc: 0.9038 - val_loss: 0.2392 - val_acc: 0.9009\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 9s - loss: 0.2385 - acc: 0.8903 - val_loss: 0.2396 - val_acc: 0.8972\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 9s - loss: 0.2266 - acc: 0.8991 - val_loss: 0.2614 - val_acc: 0.8897\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 9s - loss: 0.2255 - acc: 0.9081 - val_loss: 0.2667 - val_acc: 0.8897\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 9s - loss: 0.2454 - acc: 0.8927 - val_loss: 0.3065 - val_acc: 0.8710\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 9s - loss: 0.2208 - acc: 0.9128 - val_loss: 0.2782 - val_acc: 0.8935\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 9s - loss: 0.2226 - acc: 0.9013 - val_loss: 0.2371 - val_acc: 0.9121\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 9s - loss: 0.2297 - acc: 0.9015 - val_loss: 0.2572 - val_acc: 0.8991\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 9s - loss: 0.2037 - acc: 0.9155 - val_loss: 0.2668 - val_acc: 0.8879\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 9s - loss: 0.2164 - acc: 0.9082 - val_loss: 0.2943 - val_acc: 0.8654\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 9s - loss: 0.2387 - acc: 0.9020 - val_loss: 0.2467 - val_acc: 0.8879\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 9s - loss: 0.2068 - acc: 0.9134 - val_loss: 0.2358 - val_acc: 0.8953\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 9s - loss: 0.1901 - acc: 0.9185 - val_loss: 0.2575 - val_acc: 0.8953\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 9s - loss: 0.2308 - acc: 0.9071 - val_loss: 0.2796 - val_acc: 0.8841\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 9s - loss: 0.1906 - acc: 0.9177 - val_loss: 0.2703 - val_acc: 0.8804\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 9s - loss: 0.2400 - acc: 0.8919 - val_loss: 0.2761 - val_acc: 0.8897\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 9s - loss: 0.2082 - acc: 0.9120 - val_loss: 0.2480 - val_acc: 0.8972\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 9s - loss: 0.1957 - acc: 0.9241 - val_loss: 0.2437 - val_acc: 0.9028\n",
      "Train loss: 0.182360621955\n",
      "Train accuracy: 0.927034611787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.218782997326\n",
      "Test accuracy: 0.914018692034\n",
      "\n",
      "===================FOLD= 2\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 36s - loss: 0.7515 - acc: 0.5322 - val_loss: 0.6649 - val_acc: 0.5225\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 8s - loss: 0.6905 - acc: 0.5563 - val_loss: 0.7199 - val_acc: 0.5300\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 8s - loss: 0.5971 - acc: 0.6594 - val_loss: 0.8037 - val_acc: 0.4981\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 8s - loss: 0.6255 - acc: 0.6487 - val_loss: 0.7103 - val_acc: 0.5150\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 8s - loss: 0.5283 - acc: 0.7220 - val_loss: 0.7755 - val_acc: 0.5449\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 9s - loss: 0.5386 - acc: 0.7331 - val_loss: 0.7423 - val_acc: 0.5599\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 8s - loss: 0.4656 - acc: 0.7735 - val_loss: 0.7670 - val_acc: 0.5787\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 8s - loss: 0.4556 - acc: 0.7880 - val_loss: 0.7748 - val_acc: 0.5936\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 8s - loss: 0.4146 - acc: 0.8008 - val_loss: 0.8119 - val_acc: 0.6142\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 8s - loss: 0.4073 - acc: 0.8164 - val_loss: 0.7180 - val_acc: 0.6667\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 9s - loss: 0.3753 - acc: 0.8371 - val_loss: 0.6828 - val_acc: 0.6816\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 8s - loss: 0.3893 - acc: 0.8381 - val_loss: 0.6826 - val_acc: 0.6835\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 9s - loss: 0.3538 - acc: 0.8463 - val_loss: 0.6981 - val_acc: 0.7041\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 10s - loss: 0.3632 - acc: 0.8529 - val_loss: 0.5398 - val_acc: 0.7509\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 8s - loss: 0.3554 - acc: 0.8505 - val_loss: 0.5603 - val_acc: 0.7584\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 10s - loss: 0.3458 - acc: 0.8586 - val_loss: 0.5151 - val_acc: 0.7772\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 10s - loss: 0.3226 - acc: 0.8672 - val_loss: 0.4711 - val_acc: 0.7921\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 10s - loss: 0.2734 - acc: 0.8838 - val_loss: 0.4574 - val_acc: 0.7903\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 10s - loss: 0.3150 - acc: 0.8609 - val_loss: 0.4440 - val_acc: 0.8015\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 10s - loss: 0.3357 - acc: 0.8506 - val_loss: 0.4105 - val_acc: 0.8165\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 8s - loss: 0.2616 - acc: 0.8892 - val_loss: 0.4208 - val_acc: 0.8221\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 8s - loss: 0.2858 - acc: 0.8892 - val_loss: 0.4359 - val_acc: 0.8240\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 10s - loss: 0.2708 - acc: 0.9002 - val_loss: 0.3980 - val_acc: 0.8296\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 10s - loss: 0.2958 - acc: 0.8767 - val_loss: 0.3950 - val_acc: 0.8371\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 8s - loss: 0.2553 - acc: 0.9057 - val_loss: 0.3989 - val_acc: 0.8240\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 10s - loss: 0.2811 - acc: 0.8789 - val_loss: 0.3850 - val_acc: 0.8371\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 10s - loss: 0.2673 - acc: 0.8874 - val_loss: 0.3842 - val_acc: 0.8446\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 10s - loss: 0.2703 - acc: 0.8847 - val_loss: 0.3586 - val_acc: 0.8390\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 8s - loss: 0.2258 - acc: 0.9151 - val_loss: 0.3624 - val_acc: 0.8427\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 8s - loss: 0.2289 - acc: 0.9106 - val_loss: 0.3841 - val_acc: 0.8408\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 9s - loss: 0.2290 - acc: 0.9050 - val_loss: 0.3691 - val_acc: 0.8333\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 8s - loss: 0.2666 - acc: 0.8943 - val_loss: 0.3789 - val_acc: 0.8352\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 8s - loss: 0.2455 - acc: 0.8988 - val_loss: 0.3639 - val_acc: 0.8390\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 10s - loss: 0.2349 - acc: 0.9014 - val_loss: 0.3424 - val_acc: 0.8446\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 10s - loss: 0.2223 - acc: 0.9072 - val_loss: 0.3345 - val_acc: 0.8577\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 8s - loss: 0.2329 - acc: 0.9013 - val_loss: 0.3399 - val_acc: 0.8502\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 8s - loss: 0.2270 - acc: 0.9008 - val_loss: 0.3389 - val_acc: 0.8502\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 10s - loss: 0.2363 - acc: 0.9138 - val_loss: 0.3304 - val_acc: 0.8539\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 10s - loss: 0.2162 - acc: 0.9136 - val_loss: 0.3236 - val_acc: 0.8577\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 9s - loss: 0.2568 - acc: 0.9059 - val_loss: 0.3272 - val_acc: 0.8596\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 8s - loss: 0.2327 - acc: 0.9080 - val_loss: 0.3357 - val_acc: 0.8539\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 8s - loss: 0.2355 - acc: 0.9044 - val_loss: 0.3349 - val_acc: 0.8558\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 9s - loss: 0.2040 - acc: 0.9213 - val_loss: 0.3251 - val_acc: 0.8652\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 9s - loss: 0.2115 - acc: 0.9100 - val_loss: 0.3323 - val_acc: 0.8596\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 10s - loss: 0.2547 - acc: 0.8976 - val_loss: 0.3219 - val_acc: 0.8614\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 10s - loss: 0.2112 - acc: 0.9139 - val_loss: 0.3200 - val_acc: 0.8633\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 9s - loss: 0.1958 - acc: 0.9185 - val_loss: 0.3293 - val_acc: 0.8558\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 9s - loss: 0.2073 - acc: 0.9105 - val_loss: 0.3264 - val_acc: 0.8670\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 10s - loss: 0.1898 - acc: 0.9271 - val_loss: 0.3079 - val_acc: 0.8614\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 10s - loss: 0.2222 - acc: 0.9044 - val_loss: 0.3016 - val_acc: 0.8727\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 10s - loss: 0.2227 - acc: 0.9059 - val_loss: 0.2965 - val_acc: 0.8727\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 9s - loss: 0.1881 - acc: 0.9248 - val_loss: 0.3041 - val_acc: 0.8708\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 9s - loss: 0.1745 - acc: 0.9373 - val_loss: 0.3021 - val_acc: 0.8689\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 9s - loss: 0.1982 - acc: 0.9283 - val_loss: 0.3188 - val_acc: 0.8689\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 9s - loss: 0.1962 - acc: 0.9193 - val_loss: 0.3122 - val_acc: 0.8708\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 9s - loss: 0.1816 - acc: 0.9295 - val_loss: 0.3214 - val_acc: 0.8689\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 9s - loss: 0.1974 - acc: 0.9249 - val_loss: 0.3350 - val_acc: 0.8539\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 9s - loss: 0.1863 - acc: 0.9314 - val_loss: 0.3199 - val_acc: 0.8577\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 10s - loss: 0.2180 - acc: 0.9178 - val_loss: 0.2913 - val_acc: 0.8689\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 9s - loss: 0.2005 - acc: 0.9200 - val_loss: 0.2918 - val_acc: 0.8670\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 9s - loss: 0.1661 - acc: 0.9455 - val_loss: 0.2943 - val_acc: 0.8708\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 9s - loss: 0.1705 - acc: 0.9322 - val_loss: 0.3080 - val_acc: 0.8689\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 9s - loss: 0.1703 - acc: 0.9393 - val_loss: 0.3277 - val_acc: 0.8614\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 9s - loss: 0.1828 - acc: 0.9249 - val_loss: 0.3053 - val_acc: 0.8652\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 9s - loss: 0.1824 - acc: 0.9321 - val_loss: 0.3483 - val_acc: 0.8558\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 9s - loss: 0.1391 - acc: 0.9524 - val_loss: 0.3219 - val_acc: 0.8670\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 9s - loss: 0.1850 - acc: 0.9246 - val_loss: 0.3108 - val_acc: 0.8708\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 9s - loss: 0.1655 - acc: 0.9372 - val_loss: 0.3359 - val_acc: 0.8689\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 9s - loss: 0.1779 - acc: 0.9238 - val_loss: 0.3246 - val_acc: 0.8727\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 9s - loss: 0.1635 - acc: 0.9393 - val_loss: 0.3477 - val_acc: 0.8614\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 9s - loss: 0.1747 - acc: 0.9288 - val_loss: 0.3183 - val_acc: 0.8708\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 9s - loss: 0.1902 - acc: 0.9245 - val_loss: 0.2979 - val_acc: 0.8783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 9s - loss: 0.1783 - acc: 0.9307 - val_loss: 0.3055 - val_acc: 0.8633\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 8s - loss: 0.1649 - acc: 0.9396 - val_loss: 0.3020 - val_acc: 0.8745\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 8s - loss: 0.1567 - acc: 0.9348 - val_loss: 0.3103 - val_acc: 0.8745\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 9s - loss: 0.1628 - acc: 0.9353 - val_loss: 0.3112 - val_acc: 0.8689\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 8s - loss: 0.1546 - acc: 0.9439 - val_loss: 0.3337 - val_acc: 0.8670\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 10s - loss: 0.1578 - acc: 0.9350 - val_loss: 0.2897 - val_acc: 0.8895\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 8s - loss: 0.1870 - acc: 0.9301 - val_loss: 0.3032 - val_acc: 0.8670\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 8s - loss: 0.1706 - acc: 0.9305 - val_loss: 0.2927 - val_acc: 0.8895\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 8s - loss: 0.1638 - acc: 0.9412 - val_loss: 0.3072 - val_acc: 0.8670\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 11s - loss: 0.1773 - acc: 0.9392 - val_loss: 0.2842 - val_acc: 0.8858\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 8s - loss: 0.1651 - acc: 0.9338 - val_loss: 0.2885 - val_acc: 0.8858\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 10s - loss: 0.1631 - acc: 0.9327 - val_loss: 0.2835 - val_acc: 0.8801\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 10s - loss: 0.1463 - acc: 0.9445 - val_loss: 0.2830 - val_acc: 0.8914\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 9s - loss: 0.1404 - acc: 0.9453 - val_loss: 0.3028 - val_acc: 0.8745\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 8s - loss: 0.1513 - acc: 0.9341 - val_loss: 0.2916 - val_acc: 0.8895\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 8s - loss: 0.1325 - acc: 0.9429 - val_loss: 0.3020 - val_acc: 0.8820\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 8s - loss: 0.1660 - acc: 0.9324 - val_loss: 0.3133 - val_acc: 0.8745\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 8s - loss: 0.1349 - acc: 0.9461 - val_loss: 0.3045 - val_acc: 0.8839\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 9s - loss: 0.1485 - acc: 0.9432 - val_loss: 0.3124 - val_acc: 0.8764\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 8s - loss: 0.1581 - acc: 0.9409 - val_loss: 0.3027 - val_acc: 0.8783\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 9s - loss: 0.1354 - acc: 0.9541 - val_loss: 0.2943 - val_acc: 0.8914\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 8s - loss: 0.1388 - acc: 0.9454 - val_loss: 0.3004 - val_acc: 0.8914\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 9s - loss: 0.1308 - acc: 0.9537 - val_loss: 0.3039 - val_acc: 0.8970\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 9s - loss: 0.1307 - acc: 0.9432 - val_loss: 0.3028 - val_acc: 0.8895\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 8s - loss: 0.1397 - acc: 0.9421 - val_loss: 0.2924 - val_acc: 0.8951\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 8s - loss: 0.1314 - acc: 0.9455 - val_loss: 0.3027 - val_acc: 0.8895\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 9s - loss: 0.1570 - acc: 0.9402 - val_loss: 0.3076 - val_acc: 0.8670\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 8s - loss: 0.1253 - acc: 0.9595 - val_loss: 0.3024 - val_acc: 0.8764\n",
      "Train loss: 0.0889026318755\n",
      "Train accuracy: 0.967289720072\n",
      "Test loss: 0.283032495542\n",
      "Test accuracy: 0.891385770023\n",
      "\n",
      " Train Log Loss Validation=  0.15529905546\n",
      " Test Log Loss Validation=  0.240823360178\n"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('./model/subXception+Mobile.csv', index=False)\n",
    "# submission.to_csv('subVGG+Mobile.csv', index=False)\n",
    "# submission.to_csv('subVGG+Xception.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

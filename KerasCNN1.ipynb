{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras-CNN\n",
    "参见该文：[Keras Model for Beginners (0.210 on LB)+EDA+R&D\n",
    "](https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../Data\"]).decode(\"utf8\"))\n",
    "\n",
    "#print(check_output([\"ls\", \"/kaggle/ShipIceberg/Data\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "train = pd.read_json(\"../ShipIceberg/Data/train.json\")\n",
    "# test = pd.read_json(\"../ShipIceberg/Data/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接用read_json显示Could not reserve memory block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#test = pd.read_json(\"../ShipIceberg/Data/test.json\")\n",
    "import json\n",
    "with open('../ShipIceberg/Data/test.json', 'r') as f:\n",
    "    test = json.load(f)\n",
    "    test=pd.DataFrame(test)\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "# test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "\n",
    "\n",
    "X_band_3 = np.zeros((1604,75,75))\n",
    "for i in range(0,1604):\n",
    "    subt = abs(X_band_1[i]-X_band_2[i])\n",
    "    W1 = subt/subt.max()\n",
    "    W2=1-W1\n",
    "    X_band_3[i]=W1 * X_band_1[i]+W2 * X_band_2[i]\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "#Generate the test data\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "\n",
    "\n",
    "X_band_test_3 = np.zeros((8424,75,75))\n",
    "for i in range(0,8424):\n",
    "    subt = abs(X_band_test_1[i]-X_band_test_2[i])\n",
    "    W1 = subt/subt.max()\n",
    "    W2=1-W1\n",
    "    X_band_test_3[i]=W1 * X_band_test_1[i]+W2 * X_band_test_2[i]\n",
    "\n",
    "\n",
    "\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "del train;del test;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) \n",
    "                   for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) \n",
    "                   for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], \n",
    "                          X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our model\n",
    "def getModel():\n",
    "    #Building the model\n",
    "    gmodel=Sequential()\n",
    "    #Conv Layer 1\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 2\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 3\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 4\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "\n",
    "    #Dense Layers\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Sigmoid Layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "    \n",
    "    \n",
    "        # 使用不同的优化\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adagrad = Adagrad(lr = 1e-3, epsilon = 1e-6)\n",
    "    rmsprop = RMSprop(lr=1e-3, rho = 0.9, epsilon=1e-6)\n",
    "    adadelta = Adadelta(lr=1e-3, rho=0.95, epsilon=1e-06)\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    adamax = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "\n",
    "    mypotim=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    gmodel.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "#     gmodel.summary()\n",
    "    return gmodel\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "# file_path = \"./model/model_weights.hdf5\"\n",
    "# callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "\n",
    "# aug1\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "#                          samplewise_center=True,\n",
    "#                          samplewise_std_normalization=True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0.,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_twelve_inputs(X1, \n",
    "#                                X2, X3,X4,X5,X6,X7,X8,X9,X10,X11,X12, \n",
    "                               y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    '''\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    genX3 = gen.flow(X1,X3, batch_size=batch_size,seed=55)\n",
    "    genX4 = gen.flow(X1,X4, batch_size=batch_size,seed=55)\n",
    "    genX5 = gen.flow(X1,X5, batch_size=batch_size,seed=55)\n",
    "    genX6 = gen.flow(X1,X6, batch_size=batch_size,seed=55)\n",
    "    genX7 = gen.flow(X1,X7, batch_size=batch_size,seed=55)\n",
    "    genX8 = gen.flow(X1,X8, batch_size=batch_size,seed=55)\n",
    "    genX9 = gen.flow(X1,X9, batch_size=batch_size,seed=55)\n",
    "    genX10 = gen.flow(X1,X10, batch_size=batch_size,seed=55)\n",
    "    genX11 = gen.flow(X1,X11, batch_size=batch_size,seed=55)\n",
    "    genX12 = gen.flow(X1,X12, batch_size=batch_size,seed=55)\n",
    "#     genX13 = gen.flow(X1,X13, batch_size=batch_size,seed=55)\n",
    "'''\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            '''\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            X4i = genX4.next()\n",
    "            X5i = genX5.next()\n",
    "            X6i = genX6.next()\n",
    "            X7i = genX7.next()\n",
    "            X8i = genX8.next()\n",
    "            X9i = genX9.next()\n",
    "            X10i = genX10.next()\n",
    "            X11i = genX11.next()\n",
    "            X12i = genX12.next()\n",
    "#             X13i = genX13.next()\n",
    "'''\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], \n",
    "#                    X2i[1],X3i[1],X4i[1],X5i[1],X6i[1],X7i[1],\n",
    "#                   X8i[1],X9i[1],X10i[1],X11i[1],X12i[1]\n",
    "                  ],  X1i[1]\n",
    "\n",
    "\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_test):\n",
    "    # K-折交叉验证\n",
    "    K=10\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        '''\n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "        \n",
    "        X_min1_cv=X_min1[train_idx]\n",
    "        X_min1_hold=X_min1[test_idx]\n",
    "        \n",
    "        X_max1_cv=X_max1[train_idx]\n",
    "        X_max1_hold=X_max1[test_idx]\n",
    "        \n",
    "        X_std1_cv=X_std1[train_idx]\n",
    "        X_std1_hold=X_std1[test_idx]\n",
    "        \n",
    "        X_med1_cv=X_med1[train_idx]\n",
    "        X_med1_hold=X_med1[test_idx]\n",
    "        \n",
    "        X_mean1_cv=X_mean1[train_idx]\n",
    "        X_mean1_hold=X_mean1[test_idx]\n",
    "        \n",
    "        X_min2_cv=X_min2[train_idx]\n",
    "        X_min2_hold=X_min2[test_idx]\n",
    "        \n",
    "        X_max2_cv=X_max2[train_idx]\n",
    "        X_max2_hold=X_max2[test_idx]\n",
    "        \n",
    "        X_std2_cv=X_std2[train_idx]\n",
    "        X_std2_hold=X_std2[test_idx]\n",
    "        \n",
    "        X_med2_cv=X_med2[train_idx]\n",
    "        X_med2_hold=X_med2[test_idx]\n",
    "        \n",
    "        X_mean2_cv=X_mean2[train_idx]\n",
    "        X_mean2_hold=X_mean2[test_idx]\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #define file path and get callbacks\n",
    "        file_path = \"./model/%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_twelve_inputs(X_train_cv, \n",
    "#                                               X_angle_cv, \n",
    "#                                               X_min1_cv,X_max1_cv,X_std1_cv,X_med1_cv,X_mean1_cv,\n",
    "#                                               X_min2_cv,X_max2_cv,X_std2_cv,X_med2_cv,X_mean2_cv,\n",
    "                                              y_train_cv)\n",
    "#         galaxyModel= getVggAngleModel()\n",
    "        galaxyModel= getModel()\n",
    "        \n",
    "        # 调整训练参数\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                #steps_per_epoch=100,\n",
    "                epochs=100,\n",
    "#                 shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout],\n",
    "#                                   X_angle_hold,\n",
    "#                                  X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "#                                  X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold], \n",
    "                                 Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate(X_train_cv,\n",
    "#                                       X_angle_cv,\n",
    "#                                      X_min1_cv,X_max1_cv,X_std1_cv,X_med1_cv,X_mean1_cv,\n",
    "#                                      X_min2_cv,X_max2_cv,X_std2_cv,X_med2_cv,X_mean2_cv], \n",
    "                                     y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate(X_holdout,\n",
    "#                                      X_angle_hold,\n",
    "#                                      X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "#                                      X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold], \n",
    "                                     Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,\n",
    "#                                         X_angle_hold,\n",
    "#                                        X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "#                                        X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold\n",
    "                                       ])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, \n",
    "#                                        X_test_angle,\n",
    "#                                       X_test_min1,X_test_max1,X_test_std1,X_test_med1,X_test_mean1,\n",
    "#                                       X_test_min2,X_test_max2,X_test_std2,X_test_med2,X_test_mean2\n",
    "                                      ])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train,\n",
    "#                                         X_angle,\n",
    "#                                        X_min1,X_max1,X_std1,X_med1,X_mean1,\n",
    "#                                        X_min2,X_max2,X_std2,X_med2,X_mean2\n",
    "                                       ])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 3s - loss: 1.0629 - acc: 0.5151 - val_loss: 0.6915 - val_acc: 0.5247\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s - loss: 0.6943 - acc: 0.5326 - val_loss: 0.6847 - val_acc: 0.6111\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 1s - loss: 0.6806 - acc: 0.5579 - val_loss: 0.6752 - val_acc: 0.5741\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 1s - loss: 0.6669 - acc: 0.5431 - val_loss: 0.6625 - val_acc: 0.6667\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s - loss: 0.6428 - acc: 0.5851 - val_loss: 0.6398 - val_acc: 0.6481\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 1s - loss: 0.6329 - acc: 0.5777 - val_loss: 0.6253 - val_acc: 0.6605\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s - loss: 0.6123 - acc: 0.5814 - val_loss: 0.6070 - val_acc: 0.6481\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s - loss: 0.6042 - acc: 0.6105 - val_loss: 0.5967 - val_acc: 0.6790\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s - loss: 0.5870 - acc: 0.6535 - val_loss: 0.5896 - val_acc: 0.6543\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 1s - loss: 0.5876 - acc: 0.6516 - val_loss: 0.5870 - val_acc: 0.6543\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s - loss: 0.5704 - acc: 0.6712 - val_loss: 0.5825 - val_acc: 0.6543\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s - loss: 0.5618 - acc: 0.6708 - val_loss: 0.5766 - val_acc: 0.6543\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s - loss: 0.5789 - acc: 0.6538 - val_loss: 0.5768 - val_acc: 0.6543\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s - loss: 0.5463 - acc: 0.7111 - val_loss: 0.5688 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 1s - loss: 0.5645 - acc: 0.6571 - val_loss: 0.5738 - val_acc: 0.6605\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 1s - loss: 0.5412 - acc: 0.7099 - val_loss: 0.5722 - val_acc: 0.6605\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s - loss: 0.5596 - acc: 0.6771 - val_loss: 0.5602 - val_acc: 0.6852\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s - loss: 0.5384 - acc: 0.7118 - val_loss: 0.5602 - val_acc: 0.6728\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s - loss: 0.5394 - acc: 0.6958 - val_loss: 0.5555 - val_acc: 0.7037\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s - loss: 0.5352 - acc: 0.7460 - val_loss: 0.5353 - val_acc: 0.7469\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s - loss: 0.5148 - acc: 0.7521 - val_loss: 0.5218 - val_acc: 0.7840\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s - loss: 0.5060 - acc: 0.7594 - val_loss: 0.5151 - val_acc: 0.7593\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 1s - loss: 0.4963 - acc: 0.7601 - val_loss: 0.5031 - val_acc: 0.7840\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 1s - loss: 0.4818 - acc: 0.7742 - val_loss: 0.4867 - val_acc: 0.7963\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 1s - loss: 0.4754 - acc: 0.7657 - val_loss: 0.4921 - val_acc: 0.7593\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s - loss: 0.4694 - acc: 0.7793 - val_loss: 0.4796 - val_acc: 0.7901\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 1s - loss: 0.4598 - acc: 0.7907 - val_loss: 0.4819 - val_acc: 0.7716\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s - loss: 0.4524 - acc: 0.7889 - val_loss: 0.4695 - val_acc: 0.7840\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s - loss: 0.4628 - acc: 0.7781 - val_loss: 0.4711 - val_acc: 0.7963\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s - loss: 0.4401 - acc: 0.8015 - val_loss: 0.4524 - val_acc: 0.8148\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 1s - loss: 0.4476 - acc: 0.7856 - val_loss: 0.4573 - val_acc: 0.8148\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s - loss: 0.4391 - acc: 0.7937 - val_loss: 0.4491 - val_acc: 0.8148\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 1s - loss: 0.4380 - acc: 0.7928 - val_loss: 0.4645 - val_acc: 0.7778\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s - loss: 0.4391 - acc: 0.7939 - val_loss: 0.4429 - val_acc: 0.8272\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 1s - loss: 0.4527 - acc: 0.7823 - val_loss: 0.4381 - val_acc: 0.8210\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 1s - loss: 0.4198 - acc: 0.8083 - val_loss: 0.4557 - val_acc: 0.7901\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 1s - loss: 0.4261 - acc: 0.7980 - val_loss: 0.4382 - val_acc: 0.8395\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 1s - loss: 0.4492 - acc: 0.7956 - val_loss: 0.4497 - val_acc: 0.7901\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 1s - loss: 0.4409 - acc: 0.7859 - val_loss: 0.4245 - val_acc: 0.8333\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 1s - loss: 0.4273 - acc: 0.7983 - val_loss: 0.4369 - val_acc: 0.8333\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 1s - loss: 0.4076 - acc: 0.8146 - val_loss: 0.4451 - val_acc: 0.8210\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 1s - loss: 0.4307 - acc: 0.8038 - val_loss: 0.4467 - val_acc: 0.8086\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 1s - loss: 0.4241 - acc: 0.7983 - val_loss: 0.4354 - val_acc: 0.8086\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 1s - loss: 0.4058 - acc: 0.8104 - val_loss: 0.4222 - val_acc: 0.8333\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 1s - loss: 0.4299 - acc: 0.7989 - val_loss: 0.4249 - val_acc: 0.8333\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 1s - loss: 0.4233 - acc: 0.7997 - val_loss: 0.4474 - val_acc: 0.8025\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 1s - loss: 0.4265 - acc: 0.7952 - val_loss: 0.4376 - val_acc: 0.8272\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 1s - loss: 0.4166 - acc: 0.7955 - val_loss: 0.4473 - val_acc: 0.7963\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 1s - loss: 0.4225 - acc: 0.8063 - val_loss: 0.4258 - val_acc: 0.8333\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 1s - loss: 0.4265 - acc: 0.7997 - val_loss: 0.4351 - val_acc: 0.8148\n",
      "Train loss: 0.389213589127\n",
      "Train accuracy: 0.824549237171\n",
      "Test loss: 0.422156956023\n",
      "Test accuracy: 0.833333333333\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 3s - loss: 1.0041 - acc: 0.4904 - val_loss: 0.6924 - val_acc: 0.5155\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s - loss: 0.7039 - acc: 0.5050 - val_loss: 0.6872 - val_acc: 0.5217\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s - loss: 0.6862 - acc: 0.5281 - val_loss: 0.6784 - val_acc: 0.5466\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s - loss: 0.6745 - acc: 0.5446 - val_loss: 0.6598 - val_acc: 0.6646\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s - loss: 0.6654 - acc: 0.5336 - val_loss: 0.6401 - val_acc: 0.6957\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s - loss: 0.6380 - acc: 0.5515 - val_loss: 0.6112 - val_acc: 0.7516\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s - loss: 0.6251 - acc: 0.5734 - val_loss: 0.5898 - val_acc: 0.7391\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 1s - loss: 0.6063 - acc: 0.6014 - val_loss: 0.5727 - val_acc: 0.7453\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s - loss: 0.6004 - acc: 0.6083 - val_loss: 0.5716 - val_acc: 0.7205\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s - loss: 0.5756 - acc: 0.6730 - val_loss: 0.5504 - val_acc: 0.7391\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s - loss: 0.5911 - acc: 0.6568 - val_loss: 0.5442 - val_acc: 0.7516\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 1s - loss: 0.5686 - acc: 0.6721 - val_loss: 0.5433 - val_acc: 0.7267\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s - loss: 0.5657 - acc: 0.6803 - val_loss: 0.5277 - val_acc: 0.7516\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s - loss: 0.5639 - acc: 0.6758 - val_loss: 0.5428 - val_acc: 0.7081\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s - loss: 0.5742 - acc: 0.6652 - val_loss: 0.5252 - val_acc: 0.7329\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s - loss: 0.5353 - acc: 0.7088 - val_loss: 0.5069 - val_acc: 0.7702\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s - loss: 0.5538 - acc: 0.7036 - val_loss: 0.4991 - val_acc: 0.7702\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s - loss: 0.5257 - acc: 0.7326 - val_loss: 0.4857 - val_acc: 0.7888\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 1s - loss: 0.5292 - acc: 0.7080 - val_loss: 0.4874 - val_acc: 0.7702\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 1s - loss: 0.5218 - acc: 0.7257 - val_loss: 0.4725 - val_acc: 0.7950\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s - loss: 0.5067 - acc: 0.7437 - val_loss: 0.4599 - val_acc: 0.8075\n",
      "Epoch 22/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.4950 - acc: 0.7511"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-443f936b7d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyAngleCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#                 X_angle,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#                 X_min1,X_max1,X_std1,X_med1,X_mean1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d94a5c51ea6f>\u001b[0m in \u001b[0;36mmyAngleCV\u001b[0;34m(X_train, X_test)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;31m#                                  X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                                  Y_holdout),\n\u001b[0;32m--> 200\u001b[0;31m                 callbacks=callbacks)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m#Getting the Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jayden/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import rmsprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "preds=myAngleCV(X_train, X_test)\n",
    "#                 X_angle, \n",
    "#                 X_min1,X_max1,X_std1,X_med1,X_mean1,\n",
    "#                 X_min2,X_max2,X_std2,X_med2,X_mean2,\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('subKerasCNN1.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# target_train=train['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, \n",
    "                                                            target_train, \n",
    "                                                            random_state=1, \n",
    "                                                            train_size=0.7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#Without denoising, core features.\n",
    "import os\n",
    "gmodel=getModel()\n",
    "gmodel.fit(X_train_cv, y_train_cv,\n",
    "          batch_size=64,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "gmodel.load_weights(filepath=file_path)\n",
    "score = gmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "predicted_test=gmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
    "submission.to_csv('subKerasCNN1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

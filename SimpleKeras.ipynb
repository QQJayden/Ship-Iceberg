{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：[Keras - straightforward](https://www.kaggle.com/mihaskalic/keras-straightforward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "train = pd.read_json(\"../ShipIceberg/Data/train.json\")\n",
    "#test_df = pd.read_json(\"../ShipIceberg/Data/test.json\")\n",
    "\n",
    "import json\n",
    "with open('../ShipIceberg/Data/test.json', 'r') as f:\n",
    "    test = json.load(f)\n",
    "    test=pd.DataFrame(test)\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "# test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain: (1604, 75, 75, 2)\n",
      "Xtest: (8424, 75, 75, 2)\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis], x_band2[:, :, :, np.newaxis]], axis=-1)\n",
    "y_train = np.array(train[\"is_iceberg\"])\n",
    "print(\"Xtrain:\", X_train.shape)\n",
    "\n",
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis], x_band2[:, :, :, np.newaxis]], axis=-1)\n",
    "print(\"Xtest:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(data,label=1):\n",
    "    data['max'+str(label)] = [np.max(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['maxpos'+str(label)] = [np.argmax(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['min'+str(label)] = [np.min(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['minpos'+str(label)] = [np.argmin(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['med'+str(label)] = [np.median(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['std'+str(label)] = [np.std(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['mean'+str(label)] = [np.mean(np.array(x)) for x in data['band_'+str(label)] ]\n",
    "    data['p25_'+str(label)] = [np.sort(np.array(x))[int(0.25*75*75)] for x in data['band_'+str(label)] ]\n",
    "    data['p75_'+str(label)] = [np.sort(np.array(x))[int(0.75*75*75)] for x in data['band_'+str(label)] ]\n",
    "    data['mid50_'+str(label)] = data['p75_'+str(label)]-data['p25_'+str(label)]\n",
    "\n",
    "    return data\n",
    "\n",
    "train = get_stats(train,1)\n",
    "train = get_stats(train,2)\n",
    "X_min1 = train['min1']\n",
    "X_max1 = train['max1']\n",
    "X_std1 = train['std1']\n",
    "X_med1 = train['med1']\n",
    "X_mean1 = train['mean1']\n",
    "X_min2 = train['min2']\n",
    "X_max2 = train['max2']\n",
    "X_std2 = train['std2']\n",
    "X_med2 = train['med2']\n",
    "X_mean2 = train['mean2']\n",
    "\n",
    "test = get_stats(test,1)\n",
    "test = get_stats(test,2)\n",
    "X_test_min1 = test['min1']\n",
    "X_test_max1 = test['max1']\n",
    "X_test_std1 = test['std1']\n",
    "X_test_med1 = test['med1']\n",
    "X_test_mean1 = test['mean1']\n",
    "X_test_min2 = test['min2']\n",
    "X_test_max2 = test['max2']\n",
    "X_test_std2 = test['std2']\n",
    "X_test_med2 = test['med2']\n",
    "X_test_mean2 = test['mean2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import rmsprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.layers import Concatenate, Dense, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# ResNet\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 批处理大小的设置\n",
    "batch_size=64\n",
    "# batch_size=16\n",
    "\n",
    "# Define the image transformations here\n",
    "# 原始旋转范围10\n",
    "#gen = ImageDataGenerator(horizontal_flip = True,\n",
    "#                         vertical_flip = True,\n",
    "#                         width_shift_range = 0.,\n",
    "#                         height_shift_range = 0.,\n",
    "#                         channel_shift_range=0,\n",
    "#                         zoom_range = 0.2,\n",
    "#                         rotation_range = 10)\n",
    "\n",
    "\n",
    "\n",
    "# aug1\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0.,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "'''\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "            '''\n",
    "\n",
    "def gen_flow_for_twelve_inputs(X1, X2, X3,X4,X5,X6,X7,X8,X9,X10,X11,X12, y):\n",
    "# def gen_flow_for_twelve_inputs(X1, y):\n",
    "    gseed = 55 # 原来55\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=gseed)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=gseed)\n",
    "    genX3 = gen.flow(X1,X3, batch_size=batch_size,seed=gseed)\n",
    "    genX4 = gen.flow(X1,X4, batch_size=batch_size,seed=gseed)\n",
    "    genX5 = gen.flow(X1,X5, batch_size=batch_size,seed=gseed)\n",
    "    genX6 = gen.flow(X1,X6, batch_size=batch_size,seed=gseed)\n",
    "    genX7 = gen.flow(X1,X7, batch_size=batch_size,seed=gseed)\n",
    "    genX8 = gen.flow(X1,X8, batch_size=batch_size,seed=gseed)\n",
    "    genX9 = gen.flow(X1,X9, batch_size=batch_size,seed=gseed)\n",
    "    genX10 = gen.flow(X1,X10, batch_size=batch_size,seed=gseed)\n",
    "    genX11 = gen.flow(X1,X11, batch_size=batch_size,seed=gseed)\n",
    "    genX12 = gen.flow(X1,X12, batch_size=batch_size,seed=gseed)\n",
    "#     genX13 = gen.flow(X1,X13, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            \n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            X4i = genX4.next()\n",
    "            X5i = genX5.next()\n",
    "            X6i = genX6.next()\n",
    "            X7i = genX7.next()\n",
    "            X8i = genX8.next()\n",
    "            X9i = genX9.next()\n",
    "            X10i = genX10.next()\n",
    "            X11i = genX11.next()\n",
    "            X12i = genX12.next()\n",
    "            \n",
    "#             X13i = genX13.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1],X3i[1],X4i[1],X5i[1],X6i[1],X7i[1],\n",
    "                  X8i[1],X9i[1],X10i[1],X11i[1],X12i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "   es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "   msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "   return [es, msave]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVggAngleModel():\n",
    "    \n",
    "    \"\"\"\n",
    "    Keras Sequential model\n",
    "\n",
    "    \"\"\"\n",
    "#     input_2 = Input(shape=[1], name=\"angle\")\n",
    "#     angle_layer = Dense(1, )(input_2)\n",
    "    input_1 = Input(shape=(75,75,2))\n",
    "    \n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    input_3 = Input(shape=[1], name=\"min1\")\n",
    "    input_4 = Input(shape=[1], name=\"max1\")\n",
    "    input_5 = Input(shape=[1], name=\"std1\")\n",
    "    input_6 = Input(shape=[1], name=\"med1\")\n",
    "    input_7 = Input(shape=[1], name=\"mean1\")\n",
    "    input_8 = Input(shape=[1], name=\"min2\")\n",
    "    input_9 = Input(shape=[1], name=\"max2\")\n",
    "    input_10 = Input(shape=[1], name=\"std2\")\n",
    "    input_11 = Input(shape=[1], name=\"med2\")\n",
    "    input_12 = Input(shape=[1], name=\"mean2\")\n",
    "#     input_13 = Input(shape=[1], name=\"size\")\n",
    "    \n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    min1_layer = Dense(1, )(input_3)\n",
    "    max1_layer = Dense(1, )(input_4)\n",
    "    std1_layer = Dense(1, )(input_5)\n",
    "    med1_layer = Dense(1, )(input_6)\n",
    "    mean1_layer = Dense(1, )(input_7)\n",
    "    min2_layer = Dense(1, )(input_8)\n",
    "    max2_layer = Dense(1, )(input_9)\n",
    "    std2_layer = Dense(1, )(input_10)\n",
    "    med2_layer = Dense(1, )(input_11)\n",
    "    mean2_layer = Dense(1, )(input_12)\n",
    "#     size_layer = Dense(1, )(input_13)\n",
    "    \n",
    "#     model=Sequential()\n",
    "    \n",
    "    # Conv block 1\n",
    "    x=Conv2D(64, kernel_size=(3, 3),activation='relu')(input_1)\n",
    "    x=Conv2D(64, kernel_size=(3, 3), activation='relu' )(x)\n",
    "    x=Conv2D(64, kernel_size=(3, 3), activation='relu' )(x)\n",
    "    x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "   \n",
    "    # Conv block 2\n",
    "    x=Conv2D(128, kernel_size=(3, 3), activation='relu' )(x)\n",
    "    x=Conv2D(128, kernel_size=(3, 3), activation='relu' )(x)\n",
    "    x=Conv2D(128, kernel_size=(3, 3), activation='relu' )(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "   \n",
    "    # Conv block 3\n",
    "    x=Conv2D(128, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "   \n",
    "    #Conv block 4\n",
    "    x=Conv2D(256, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "   \n",
    "    # Flatten before dense\n",
    "    x=Flatten()(x)\n",
    "    \n",
    "#     merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer,\n",
    "                             min1_layer,max1_layer,std1_layer,med1_layer,mean1_layer,\n",
    "                            min2_layer,max2_layer,std2_layer,med2_layer,mean2_layer])\n",
    "\n",
    "    #Dense 1\n",
    "    merge_one = Dense(1024, activation='relu')(merge_one)\n",
    "    merge_one = Dropout(0.4)(merge_one)\n",
    "\n",
    "    #Dense 2\n",
    "    merge_one = Dense(512, activation='relu')(merge_one)\n",
    "    merge_one = Dropout(0.2)(merge_one)\n",
    "\n",
    "    # Output \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "#     model = Model(input=[input_1, input_2], output=predictions)\n",
    "    model = Model(input=[input_1, input_2,input_3,input_4,input_5,input_6,\n",
    "                        input_7,input_8,input_9,input_10,input_11,input_12], \n",
    "                  output=predictions)\n",
    "\n",
    "    optimizer = Adam(lr=0.0001, decay=0.0)\n",
    "    sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    input_1 = Input(shape=(75,75,2))\n",
    "    BD = 64\n",
    "    \n",
    "    conv1 = Convolution2D(BD,3,3,border_mode='same',name='conv_1_1')(input_1)\n",
    "    conv1=BatchNormalization(axis=1)(conv1)\n",
    "    conv1=Activation('relu')(conv1)\n",
    "    \n",
    "    conv1 = Convolution2D(BD,3,3,border_mode='same',name='conv_1_2')(conv1)\n",
    "    conv1=BatchNormalization(axis=1)(conv1)\n",
    "    conv1=Activation('relu')(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2),name='pool_1')(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(2*BD,3,3,border_mode='same',name='conv_2_1')(pool1)\n",
    "    conv2=BatchNormalization(axis=1)(conv2)\n",
    "    conv2=Activation('relu')(conv2)\n",
    "\n",
    "    conv2 = Convolution2D(2*BD,3,3,border_mode='same',name='conv_2_2')(conv2)\n",
    "    conv2=BatchNormalization(axis=1)(conv2)\n",
    "    conv2=Activation('relu')(conv2)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2),name='pool_2')(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(4*BD,3,3,border_mode='same',name='conv_3_1')(pool2)\n",
    "    conv3 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "\n",
    "    conv3 = Convolution2D(4*BD,3,3,border_mode='same',name='conv_3_2')(conv3)\n",
    "    conv3=BatchNormalization(axis=1)(conv3)\n",
    "    conv3=Activation('relu')(conv3)\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2),name='pool_3')(conv3)\n",
    "\n",
    "\n",
    "    pool3 = Convolution2D(8*BD,3,3,border_mode='same')(pool3)\n",
    "    pool3=BatchNormalization(axis=1)(pool3)\n",
    "    pool3=Activation('relu')(pool3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2),name='pool_3')(conv3)\n",
    "\n",
    "\n",
    "    pool3 = Convolution2D(8*BD,3,3,border_mode='same')(pool3)\n",
    "    pool3=BatchNormalization(axis=1)(pool3)\n",
    "    pool3=Activation('relu')(pool3)\n",
    "\n",
    "    x=Dropout(0.2)(pool3)\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "#     merge_one = x\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "#     merge_one = Dense(1024, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "#     merge_one = Dense(32, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[input_1, input_2], output=predictions)\n",
    "#     model = Model(input=[base_model.input], output=predictions)\n",
    "#     model = Model(input=[input_tensor, input_2], output=predictions)\n",
    "    \n",
    "    # 使用不同的优化\n",
    "    sgd = SGD(lr=8e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adagrad = Adagrad(lr = 1e-3, epsilon = 1e-6)\n",
    "    rmsprop = RMSprop(lr=1e-3, rho = 0.9, epsilon=1e-6)\n",
    "    adadelta = Adadelta(lr=1e-3, rho=0.95, epsilon=1e-06)\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    adamax = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    \n",
    "    # 更换loss\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, \n",
    "              X_min1,X_max1,X_std1,X_med1,X_mean1,\n",
    "              X_min2,X_max2,X_std2,X_med2,X_mean2,\n",
    "              X_test):\n",
    "    # K-折交叉验证\n",
    "    K=4\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=2017).split(X_train, target_train)) # 原16\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "        \n",
    "        X_min1_cv=X_min1[train_idx]\n",
    "        X_min1_hold=X_min1[test_idx]\n",
    "        \n",
    "        X_max1_cv=X_max1[train_idx]\n",
    "        X_max1_hold=X_max1[test_idx]\n",
    "        \n",
    "        X_std1_cv=X_std1[train_idx]\n",
    "        X_std1_hold=X_std1[test_idx]\n",
    "        \n",
    "        X_med1_cv=X_med1[train_idx]\n",
    "        X_med1_hold=X_med1[test_idx]\n",
    "        \n",
    "        X_mean1_cv=X_mean1[train_idx]\n",
    "        X_mean1_hold=X_mean1[test_idx]\n",
    "        \n",
    "        X_min2_cv=X_min2[train_idx]\n",
    "        X_min2_hold=X_min2[test_idx]\n",
    "        \n",
    "        X_max2_cv=X_max2[train_idx]\n",
    "        X_max2_hold=X_max2[test_idx]\n",
    "        \n",
    "        X_std2_cv=X_std2[train_idx]\n",
    "        X_std2_hold=X_std2[test_idx]\n",
    "        \n",
    "        X_med2_cv=X_med2[train_idx]\n",
    "        X_med2_hold=X_med2[test_idx]\n",
    "        \n",
    "        X_mean2_cv=X_mean2[train_idx]\n",
    "        X_mean2_hold=X_mean2[test_idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"./model/%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_twelve_inputs(X_train_cv, X_angle_cv, \n",
    "                                              X_min1_cv,X_max1_cv,X_std1_cv,X_med1_cv,X_mean1_cv,\n",
    "                                              X_min2_cv,X_max2_cv,X_std2_cv,X_med2_cv,X_mean2_cv,\n",
    "                                              y_train_cv)\n",
    "#         gen_flow = gen_flow_for_twelve_inputs(X_train_cv,y_train_cv)\n",
    "    \n",
    "        galaxyModel= getVggAngleModel()\n",
    "        \n",
    "#         gen_flow1=[gen_flow,X_angle_cv, X_min1_cv,X_max1_cv,X_std1_cv,X_med1_cv,X_mean1_cv,\n",
    "#                    X_min2_cv,X_max2_cv,X_std2_cv,X_med2_cv,X_mean2_cv]\n",
    "        \n",
    "        # 调整训练参数\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "#                 steps_per_epoch=24,\n",
    "                steps_per_epoch = len(X_train_cv)//batch_size,\n",
    "                #steps_per_epoch=100,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold,\n",
    "                                 X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "                                 X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold], \n",
    "                                 Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv,\n",
    "                                     X_min1_cv,X_max1_cv,X_std1_cv,X_med1_cv,X_mean1_cv,\n",
    "                                     X_min2_cv,X_max2_cv,X_std2_cv,X_med2_cv,X_mean2_cv], \n",
    "                                     y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold,\n",
    "                                     X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "                                     X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold], \n",
    "                                     Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold,\n",
    "                                       X_min1_hold,X_max1_hold,X_std1_hold,X_med1_hold,X_mean1_hold,\n",
    "                                       X_min2_hold,X_max2_hold,X_std2_hold,X_med2_hold,X_mean2_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle,\n",
    "                                      X_test_min1,X_test_max1,X_test_std1,X_test_med1,X_test_mean1,\n",
    "                                      X_test_min2,X_test_max2,X_test_std2,X_test_med2,X_test_mean2])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle,\n",
    "                                       X_min1,X_max1,X_std1,X_med1,X_mean1,\n",
    "                                       X_min2,X_max2,X_std2,X_med2,X_mean2])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_valid_pred_log,y_test_pred_log"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    # K-折交叉验证\n",
    "    K=3\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=2017).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"./model/%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        \n",
    "        # 调整训练参数\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=len(X_train_cv)//batch_size,\n",
    "                #steps_per_epoch=100,\n",
    "                epochs=200,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (1202, 75, 75, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 9s - loss: 0.8994 - acc: 0.5104 - val_loss: 0.6392 - val_acc: 0.5323\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 6s - loss: 0.8325 - acc: 0.5383 - val_loss: 0.6023 - val_acc: 0.6418\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 6s - loss: 0.7453 - acc: 0.6005 - val_loss: 0.5996 - val_acc: 0.6468\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 6s - loss: 0.7237 - acc: 0.6006 - val_loss: 0.5879 - val_acc: 0.6318\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 6s - loss: 0.7177 - acc: 0.6012 - val_loss: 0.5875 - val_acc: 0.6393\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 6s - loss: 0.7257 - acc: 0.5967 - val_loss: 0.5874 - val_acc: 0.6468\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 6s - loss: 0.6913 - acc: 0.6408 - val_loss: 0.5840 - val_acc: 0.6468\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 6s - loss: 0.7067 - acc: 0.6004 - val_loss: 0.5798 - val_acc: 0.6517\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 7s - loss: 0.6628 - acc: 0.6325 - val_loss: 0.5793 - val_acc: 0.6443\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 7s - loss: 0.6859 - acc: 0.6137 - val_loss: 0.5790 - val_acc: 0.6542\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 6s - loss: 0.6450 - acc: 0.6513 - val_loss: 0.5845 - val_acc: 0.6517\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 6s - loss: 0.6809 - acc: 0.6134 - val_loss: 0.5702 - val_acc: 0.6542\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 6s - loss: 0.6481 - acc: 0.6302 - val_loss: 0.5887 - val_acc: 0.6517\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 7s - loss: 0.6721 - acc: 0.6093 - val_loss: 0.5808 - val_acc: 0.6542\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 6s - loss: 0.6633 - acc: 0.6208 - val_loss: 0.5651 - val_acc: 0.6493\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 6s - loss: 0.6414 - acc: 0.6339 - val_loss: 0.5644 - val_acc: 0.6493\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 6s - loss: 0.6357 - acc: 0.6319 - val_loss: 0.5640 - val_acc: 0.6493\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 6s - loss: 0.6441 - acc: 0.6308 - val_loss: 0.5650 - val_acc: 0.6542\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 7s - loss: 0.6203 - acc: 0.6547 - val_loss: 0.5678 - val_acc: 0.6567\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 7s - loss: 0.6136 - acc: 0.6476 - val_loss: 0.5605 - val_acc: 0.6542\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 7s - loss: 0.6192 - acc: 0.6310 - val_loss: 0.5594 - val_acc: 0.6542\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 6s - loss: 0.6248 - acc: 0.6340 - val_loss: 0.5628 - val_acc: 0.6667\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 7s - loss: 0.6068 - acc: 0.6422 - val_loss: 0.5630 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 6s - loss: 0.6139 - acc: 0.6413 - val_loss: 0.5592 - val_acc: 0.6567\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 7s - loss: 0.6088 - acc: 0.6552 - val_loss: 0.5531 - val_acc: 0.6517\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 6s - loss: 0.6112 - acc: 0.6460 - val_loss: 0.5630 - val_acc: 0.6741\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 6s - loss: 0.6079 - acc: 0.6558 - val_loss: 0.5583 - val_acc: 0.6667\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 6s - loss: 0.5867 - acc: 0.6737 - val_loss: 0.5533 - val_acc: 0.6592\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 7s - loss: 0.6175 - acc: 0.6375 - val_loss: 0.5590 - val_acc: 0.6667\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 7s - loss: 0.6054 - acc: 0.6547 - val_loss: 0.5557 - val_acc: 0.6642\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 6s - loss: 0.6069 - acc: 0.6440 - val_loss: 0.5567 - val_acc: 0.6766\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 6s - loss: 0.5998 - acc: 0.6565 - val_loss: 0.5466 - val_acc: 0.6567\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 6s - loss: 0.6071 - acc: 0.6404 - val_loss: 0.5516 - val_acc: 0.6766\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 7s - loss: 0.6084 - acc: 0.6523 - val_loss: 0.5507 - val_acc: 0.6766\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 8s - loss: 0.6034 - acc: 0.6460 - val_loss: 0.5479 - val_acc: 0.6692\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 6s - loss: 0.5939 - acc: 0.6569 - val_loss: 0.5475 - val_acc: 0.6716\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 6s - loss: 0.5828 - acc: 0.6625 - val_loss: 0.5545 - val_acc: 0.6841\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 7s - loss: 0.6026 - acc: 0.6512 - val_loss: 0.5448 - val_acc: 0.6716\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 7s - loss: 0.5950 - acc: 0.6510 - val_loss: 0.5485 - val_acc: 0.6816\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 7s - loss: 0.6041 - acc: 0.6349 - val_loss: 0.5456 - val_acc: 0.6816\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 6s - loss: 0.5926 - acc: 0.6526 - val_loss: 0.5476 - val_acc: 0.6816\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 6s - loss: 0.6009 - acc: 0.6486 - val_loss: 0.5459 - val_acc: 0.6816\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 7s - loss: 0.6016 - acc: 0.6400 - val_loss: 0.5447 - val_acc: 0.6791\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 8s - loss: 0.5786 - acc: 0.6613 - val_loss: 0.5440 - val_acc: 0.6816\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 7s - loss: 0.5743 - acc: 0.6784 - val_loss: 0.5492 - val_acc: 0.6866\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 7s - loss: 0.5658 - acc: 0.6782 - val_loss: 0.5438 - val_acc: 0.6841\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 6s - loss: 0.5930 - acc: 0.6489 - val_loss: 0.5447 - val_acc: 0.6891\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 6s - loss: 0.5788 - acc: 0.6777 - val_loss: 0.5400 - val_acc: 0.6915\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 7s - loss: 0.5795 - acc: 0.6723 - val_loss: 0.5434 - val_acc: 0.6891\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 7s - loss: 0.6093 - acc: 0.6406 - val_loss: 0.5423 - val_acc: 0.6891\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 6s - loss: 0.5687 - acc: 0.6774 - val_loss: 0.5459 - val_acc: 0.6891\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 6s - loss: 0.5831 - acc: 0.6745 - val_loss: 0.5393 - val_acc: 0.6891\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 7s - loss: 0.5754 - acc: 0.6889 - val_loss: 0.5479 - val_acc: 0.6965\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 6s - loss: 0.5587 - acc: 0.6760 - val_loss: 0.5445 - val_acc: 0.6940\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 7s - loss: 0.5730 - acc: 0.6786 - val_loss: 0.5380 - val_acc: 0.7015\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 8s - loss: 0.5729 - acc: 0.6656 - val_loss: 0.5417 - val_acc: 0.6965\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 6s - loss: 0.5804 - acc: 0.6471 - val_loss: 0.5433 - val_acc: 0.6965\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 7s - loss: 0.5799 - acc: 0.6649 - val_loss: 0.5377 - val_acc: 0.7015\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 7s - loss: 0.5735 - acc: 0.6669 - val_loss: 0.5420 - val_acc: 0.7015\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 7s - loss: 0.5559 - acc: 0.6841 - val_loss: 0.5341 - val_acc: 0.7040\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 7s - loss: 0.5633 - acc: 0.6823 - val_loss: 0.5389 - val_acc: 0.7090\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 8s - loss: 0.5708 - acc: 0.6652 - val_loss: 0.5335 - val_acc: 0.7065\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 7s - loss: 0.5937 - acc: 0.6636 - val_loss: 0.5406 - val_acc: 0.7139\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 7s - loss: 0.5636 - acc: 0.6845 - val_loss: 0.5333 - val_acc: 0.7065\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 6s - loss: 0.5651 - acc: 0.6762 - val_loss: 0.5366 - val_acc: 0.7065\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 6s - loss: 0.5817 - acc: 0.6712 - val_loss: 0.5339 - val_acc: 0.7065\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 8s - loss: 0.5788 - acc: 0.6679 - val_loss: 0.5433 - val_acc: 0.7065\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 8s - loss: 0.5555 - acc: 0.6965 - val_loss: 0.5348 - val_acc: 0.7114\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 6s - loss: 0.5643 - acc: 0.6860 - val_loss: 0.5406 - val_acc: 0.7090\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 7s - loss: 0.5674 - acc: 0.6742 - val_loss: 0.5280 - val_acc: 0.7040\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 7s - loss: 0.5766 - acc: 0.6677 - val_loss: 0.5407 - val_acc: 0.7090\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 7s - loss: 0.5528 - acc: 0.6980 - val_loss: 0.5309 - val_acc: 0.7090\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 8s - loss: 0.5659 - acc: 0.6916 - val_loss: 0.5370 - val_acc: 0.7090\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 7s - loss: 0.5770 - acc: 0.6651 - val_loss: 0.5320 - val_acc: 0.7139\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 6s - loss: 0.5668 - acc: 0.6860 - val_loss: 0.5373 - val_acc: 0.7114\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 6s - loss: 0.5701 - acc: 0.6788 - val_loss: 0.5340 - val_acc: 0.7139\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 7s - loss: 0.5584 - acc: 0.6910 - val_loss: 0.5296 - val_acc: 0.7114\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 7s - loss: 0.5578 - acc: 0.6875 - val_loss: 0.5295 - val_acc: 0.7164\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 6s - loss: 0.5624 - acc: 0.6924 - val_loss: 0.5335 - val_acc: 0.7139\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 6s - loss: 0.5418 - acc: 0.6936 - val_loss: 0.5311 - val_acc: 0.7114\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 7s - loss: 0.5472 - acc: 0.6903 - val_loss: 0.5346 - val_acc: 0.7164\n",
      "Train loss: 0.529585602775\n",
      "Train accuracy: 0.714642263044\n",
      "Test loss: 0.528033266613\n",
      "Test accuracy: 0.703980099577\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (1203, 75, 75, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 8s - loss: 1.0235 - acc: 0.5469 - val_loss: 0.6291 - val_acc: 0.6883\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 6s - loss: 0.9033 - acc: 0.5601 - val_loss: 0.5875 - val_acc: 0.6683\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 7s - loss: 0.8603 - acc: 0.5891 - val_loss: 0.5895 - val_acc: 0.6733\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 7s - loss: 0.8321 - acc: 0.5928 - val_loss: 0.5813 - val_acc: 0.6608\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 7s - loss: 0.8175 - acc: 0.5789 - val_loss: 0.5800 - val_acc: 0.6459\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 7s - loss: 0.7546 - acc: 0.6210 - val_loss: 0.5739 - val_acc: 0.6633\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 7s - loss: 0.7311 - acc: 0.6169 - val_loss: 0.5737 - val_acc: 0.6683\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 7s - loss: 0.7217 - acc: 0.6241 - val_loss: 0.5803 - val_acc: 0.6708\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 7s - loss: 0.7083 - acc: 0.6217 - val_loss: 0.5730 - val_acc: 0.6683\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 7s - loss: 0.7058 - acc: 0.6201 - val_loss: 0.5957 - val_acc: 0.6733\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 7s - loss: 0.7082 - acc: 0.6095 - val_loss: 0.5748 - val_acc: 0.6658\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 7s - loss: 0.7085 - acc: 0.6047 - val_loss: 0.5781 - val_acc: 0.6783\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 6s - loss: 0.6650 - acc: 0.6299 - val_loss: 0.5735 - val_acc: 0.6833\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 7s - loss: 0.6736 - acc: 0.6162 - val_loss: 0.6002 - val_acc: 0.6858\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 8s - loss: 0.6770 - acc: 0.6303 - val_loss: 0.5649 - val_acc: 0.6858\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 6s - loss: 0.6506 - acc: 0.6382 - val_loss: 0.5851 - val_acc: 0.6833\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 6s - loss: 0.6617 - acc: 0.6403 - val_loss: 0.5649 - val_acc: 0.6833\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 6s - loss: 0.6389 - acc: 0.6447 - val_loss: 0.5698 - val_acc: 0.6783\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 7s - loss: 0.6464 - acc: 0.6328 - val_loss: 0.5652 - val_acc: 0.6758\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 8s - loss: 0.6396 - acc: 0.6354 - val_loss: 0.5571 - val_acc: 0.6908\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 7s - loss: 0.6492 - acc: 0.6098 - val_loss: 0.5653 - val_acc: 0.6883\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 6s - loss: 0.6269 - acc: 0.6497 - val_loss: 0.5585 - val_acc: 0.6858\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 7s - loss: 0.6499 - acc: 0.6239 - val_loss: 0.5662 - val_acc: 0.6908\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 7s - loss: 0.6433 - acc: 0.6243 - val_loss: 0.5595 - val_acc: 0.6883\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 8s - loss: 0.6334 - acc: 0.6256 - val_loss: 0.5590 - val_acc: 0.6908\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 7s - loss: 0.6391 - acc: 0.6262 - val_loss: 0.5625 - val_acc: 0.6933\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 7s - loss: 0.6208 - acc: 0.6418 - val_loss: 0.5662 - val_acc: 0.6908\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 7s - loss: 0.6310 - acc: 0.6215 - val_loss: 0.5583 - val_acc: 0.6908\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 7s - loss: 0.6087 - acc: 0.6536 - val_loss: 0.5739 - val_acc: 0.6908\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 8s - loss: 0.6230 - acc: 0.6486 - val_loss: 0.5681 - val_acc: 0.6883\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 8s - loss: 0.6028 - acc: 0.6536 - val_loss: 0.5660 - val_acc: 0.6883\n",
      "Train loss: 0.560690913811\n",
      "Train accuracy: 0.670822942817\n",
      "Test loss: 0.557122009056\n",
      "Test accuracy: 0.690773067703\n",
      "\n",
      "===================FOLD= 2\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s - loss: 0.9727 - acc: 0.5017 - val_loss: 0.6887 - val_acc: 0.5686\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 6s - loss: 0.8926 - acc: 0.5348 - val_loss: 0.6640 - val_acc: 0.6384\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 7s - loss: 0.8670 - acc: 0.5350 - val_loss: 0.6402 - val_acc: 0.6883\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 7s - loss: 0.8468 - acc: 0.5281 - val_loss: 0.6403 - val_acc: 0.6808\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 8s - loss: 0.8139 - acc: 0.5557 - val_loss: 0.6335 - val_acc: 0.6858\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 7s - loss: 0.7998 - acc: 0.5624 - val_loss: 0.6266 - val_acc: 0.6908\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 6s - loss: 0.7864 - acc: 0.5557 - val_loss: 0.6273 - val_acc: 0.6908\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 7s - loss: 0.7506 - acc: 0.5626 - val_loss: 0.6375 - val_acc: 0.6808\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 8s - loss: 0.7067 - acc: 0.5965 - val_loss: 0.6077 - val_acc: 0.6708\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 8s - loss: 0.7119 - acc: 0.5897 - val_loss: 0.6238 - val_acc: 0.6933\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 7s - loss: 0.6934 - acc: 0.6054 - val_loss: 0.6080 - val_acc: 0.6733\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 7s - loss: 0.6957 - acc: 0.6164 - val_loss: 0.6162 - val_acc: 0.6933\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 7s - loss: 0.7448 - acc: 0.5711 - val_loss: 0.6114 - val_acc: 0.6808\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 6s - loss: 0.7189 - acc: 0.5854 - val_loss: 0.6168 - val_acc: 0.6933\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 8s - loss: 0.6710 - acc: 0.6049 - val_loss: 0.5974 - val_acc: 0.6758\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 7s - loss: 0.6590 - acc: 0.6295 - val_loss: 0.6329 - val_acc: 0.6858\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 6s - loss: 0.6781 - acc: 0.6102 - val_loss: 0.6136 - val_acc: 0.6908\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 7s - loss: 0.6801 - acc: 0.5976 - val_loss: 0.6171 - val_acc: 0.6958\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 7s - loss: 0.6754 - acc: 0.6111 - val_loss: 0.6045 - val_acc: 0.6858\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 7s - loss: 0.6747 - acc: 0.6128 - val_loss: 0.6168 - val_acc: 0.6958\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 7s - loss: 0.6441 - acc: 0.6215 - val_loss: 0.6211 - val_acc: 0.6808\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 6s - loss: 0.6445 - acc: 0.6484 - val_loss: 0.6096 - val_acc: 0.6933\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 6s - loss: 0.6530 - acc: 0.6111 - val_loss: 0.6229 - val_acc: 0.6883\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 7s - loss: 0.6265 - acc: 0.6206 - val_loss: 0.6167 - val_acc: 0.6933\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 6s - loss: 0.6449 - acc: 0.6342 - val_loss: 0.6220 - val_acc: 0.6883\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 7s - loss: 0.6315 - acc: 0.6414 - val_loss: 0.6295 - val_acc: 0.6908\n",
      "Train loss: 0.593191182821\n",
      "Train accuracy: 0.671654197764\n",
      "Test loss: 0.59740294334\n",
      "Test accuracy: 0.675810474038\n",
      "\n",
      "===================FOLD= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayden/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:787: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (1204, 75, 75, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 8s - loss: 1.2320 - acc: 0.4696 - val_loss: 0.6923 - val_acc: 0.5125\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 6s - loss: 0.9808 - acc: 0.5293 - val_loss: 0.6012 - val_acc: 0.6725\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 7s - loss: 0.8802 - acc: 0.5784 - val_loss: 0.5908 - val_acc: 0.6550\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 8s - loss: 0.8098 - acc: 0.5858 - val_loss: 0.5901 - val_acc: 0.6700\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 7s - loss: 0.7480 - acc: 0.6293 - val_loss: 0.5828 - val_acc: 0.6600\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 6s - loss: 0.7690 - acc: 0.6128 - val_loss: 0.5797 - val_acc: 0.6600\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 7s - loss: 0.6926 - acc: 0.6497 - val_loss: 0.5826 - val_acc: 0.6650\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 7s - loss: 0.6728 - acc: 0.6526 - val_loss: 0.5893 - val_acc: 0.6750\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 8s - loss: 0.7180 - acc: 0.6142 - val_loss: 0.5774 - val_acc: 0.6625\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 8s - loss: 0.7101 - acc: 0.6296 - val_loss: 0.5846 - val_acc: 0.6800\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 6s - loss: 0.7007 - acc: 0.6112 - val_loss: 0.5769 - val_acc: 0.6725\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 7s - loss: 0.6907 - acc: 0.6276 - val_loss: 0.5730 - val_acc: 0.6625\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 7s - loss: 0.7215 - acc: 0.6085 - val_loss: 0.5755 - val_acc: 0.6750\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 7s - loss: 0.6828 - acc: 0.6125 - val_loss: 0.5877 - val_acc: 0.6750\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 8s - loss: 0.6646 - acc: 0.6360 - val_loss: 0.5673 - val_acc: 0.6675\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 6s - loss: 0.6705 - acc: 0.6304 - val_loss: 0.5666 - val_acc: 0.6625\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 6s - loss: 0.6569 - acc: 0.6222 - val_loss: 0.5671 - val_acc: 0.6875\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 7s - loss: 0.6599 - acc: 0.6417 - val_loss: 0.5654 - val_acc: 0.6725\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 7s - loss: 0.6598 - acc: 0.6181 - val_loss: 0.5732 - val_acc: 0.6850\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 8s - loss: 0.6721 - acc: 0.6233 - val_loss: 0.5637 - val_acc: 0.6675\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 7s - loss: 0.6569 - acc: 0.6229 - val_loss: 0.5668 - val_acc: 0.6850\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 7s - loss: 0.6226 - acc: 0.6681 - val_loss: 0.5670 - val_acc: 0.6850\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 6s - loss: 0.6470 - acc: 0.6255 - val_loss: 0.5650 - val_acc: 0.6825\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 7s - loss: 0.6530 - acc: 0.6270 - val_loss: 0.5627 - val_acc: 0.6900\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 8s - loss: 0.6412 - acc: 0.6438 - val_loss: 0.5706 - val_acc: 0.6850\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 7s - loss: 0.6430 - acc: 0.6365 - val_loss: 0.5657 - val_acc: 0.6900\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 7s - loss: 0.6145 - acc: 0.6620 - val_loss: 0.5738 - val_acc: 0.6850\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 7s - loss: 0.6379 - acc: 0.6372 - val_loss: 0.5629 - val_acc: 0.6875\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 7s - loss: 0.6320 - acc: 0.6455 - val_loss: 0.5731 - val_acc: 0.6800\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 7s - loss: 0.6443 - acc: 0.6304 - val_loss: 0.5742 - val_acc: 0.6750\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 7s - loss: 0.6163 - acc: 0.6366 - val_loss: 0.5602 - val_acc: 0.6925\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 6s - loss: 0.5994 - acc: 0.6665 - val_loss: 0.5702 - val_acc: 0.6850\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 7s - loss: 0.6066 - acc: 0.6532 - val_loss: 0.5697 - val_acc: 0.6825\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 7s - loss: 0.6177 - acc: 0.6496 - val_loss: 0.5590 - val_acc: 0.6750\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 8s - loss: 0.6246 - acc: 0.6371 - val_loss: 0.5679 - val_acc: 0.6800\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 7s - loss: 0.6208 - acc: 0.6273 - val_loss: 0.5593 - val_acc: 0.6900\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 7s - loss: 0.6065 - acc: 0.6438 - val_loss: 0.5655 - val_acc: 0.6825\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 6s - loss: 0.6055 - acc: 0.6506 - val_loss: 0.5601 - val_acc: 0.6850\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 7s - loss: 0.6182 - acc: 0.6380 - val_loss: 0.5623 - val_acc: 0.6825\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 8s - loss: 0.6075 - acc: 0.6349 - val_loss: 0.5668 - val_acc: 0.6850\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 8s - loss: 0.5850 - acc: 0.6498 - val_loss: 0.5596 - val_acc: 0.6825\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 7s - loss: 0.6013 - acc: 0.6510 - val_loss: 0.5604 - val_acc: 0.6825\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 7s - loss: 0.6061 - acc: 0.6231 - val_loss: 0.5601 - val_acc: 0.6875\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 7s - loss: 0.5807 - acc: 0.6723 - val_loss: 0.5584 - val_acc: 0.6850\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 7s - loss: 0.6231 - acc: 0.6200 - val_loss: 0.5572 - val_acc: 0.6850\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 8s - loss: 0.5847 - acc: 0.6557 - val_loss: 0.5611 - val_acc: 0.6850\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 7s - loss: 0.6229 - acc: 0.6335 - val_loss: 0.5619 - val_acc: 0.6850\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 7s - loss: 0.5941 - acc: 0.6468 - val_loss: 0.5609 - val_acc: 0.6850\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 7s - loss: 0.5865 - acc: 0.6651 - val_loss: 0.5627 - val_acc: 0.6800\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 7s - loss: 0.6007 - acc: 0.6440 - val_loss: 0.5632 - val_acc: 0.6800\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 7s - loss: 0.5805 - acc: 0.6589 - val_loss: 0.5602 - val_acc: 0.6825\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 8s - loss: 0.6015 - acc: 0.6428 - val_loss: 0.5596 - val_acc: 0.6775\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 7s - loss: 0.5789 - acc: 0.6509 - val_loss: 0.5633 - val_acc: 0.6775\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 6s - loss: 0.5893 - acc: 0.6647 - val_loss: 0.5628 - val_acc: 0.6775\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 7s - loss: 0.5905 - acc: 0.6571 - val_loss: 0.5585 - val_acc: 0.6750\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 7s - loss: 0.5823 - acc: 0.6618 - val_loss: 0.5584 - val_acc: 0.6750\n",
      "Train loss: 0.555464407534\n",
      "Train accuracy: 0.685215946943\n",
      "Test loss: 0.557158296108\n",
      "Test accuracy: 0.685\n",
      "\n",
      " Train Log Loss Validation=  0.555334900021\n",
      " Test Log Loss Validation=  0.55991097476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# preds=myAngleCV(X_train, X_angle, X_test)\n",
    "train_preds,test_preds=myAngleCV(X_train, X_angle, \n",
    "                X_min1,X_max1,X_std1,X_med1,X_mean1,\n",
    "                X_min2,X_max2,X_std2,X_med2,X_mean2,\n",
    "                X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('./submission/subSimpleKeras.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
